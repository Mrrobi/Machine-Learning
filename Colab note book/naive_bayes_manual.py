# -*- coding: utf-8 -*-
"""Naive bayes Manual

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qo_Q9tSZsWlFBuGruMhwumd7NN5eTidS

# Data And library load
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from collections import Counter
from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,matthews_corrcoef

data = pd.read_csv('/content/kr-vs-kp.csv')
data

X = data.loc[:,data.columns!='label'] # Features 
y = data['label'] # Labels

y

x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.25)
x_train_s,x_test_s,y_train_s,y_test_s = train_test_split(X,y,test_size=0.25,stratify=y)
print('xtrain',x_train.shape)

"""# Naive  Bayes Model """

class naivebayes:
  prob_dict = {}
  def __init__(self):
    plabel1=0
    plabel2=0
    
  def tebul(self,df,col,sample):
    won = 0
    nowin = 0
    for i in range(len(df)):
      if(df[col][i]==sample):
        if(df['label'][i]=='won'):
          won+=1
        else:
          nowin+=1
    return won,nowin
  def fit(self,features,label):
    count_label = Counter(label) # total count of both labels
    self.plabel1 = count_label['won']/len(label) # probality of label 1 
    self.plabel2 = count_label['nowin']/len(label) # probality of label 2
    for col in features:
      self.prob_dict[col] = {}
      sample_count = Counter(features[col])
      frame = [features[col],label]
      fet_leb = pd.concat(frame,axis=1)
      fet_leb = fet_leb.reset_index(drop=True)
      unik_values = features[col].unique()
      for i in range(len(unik_values)):
        won, nowin = self.tebul(fet_leb,col,unik_values[i])
        pwon = won/count_label['won']
        pnowin = nowin/count_label['nowin']
        self.prob_dict[col][unik_values[i]] = []
        self.prob_dict[col][unik_values[i]].append(pwon)
        self.prob_dict[col][unik_values[i]].append(pnowin)
  

  def predict(self,features):
    features = features.reset_index(drop=True)
    prediction = []
    colum = features.columns
    for i in range(len(features)):
      pwon = self.plabel1
      pnowin = self.plabel2
      for col in colum:
        pwon*= self.prob_dict[col][features[col][i]][0]
        pnowin*= self.prob_dict[col][features[col][i]][1]
      if(pwon>pnowin):
        prediction.append('won')
      else:
        prediction.append('nowin')
    return prediction

"""# Use section"""

clf1 = naivebayes()
clf2 = naivebayes()

clf1.fit(x_train,y_train)
clf2.fit(x_train_s,y_train_s)

y_predict = clf1.predict(x_test)
y_predict_s = clf2.predict(x_test_s)

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
encoder.fit(y_test)
y_true = encoder.transform(y_test)
y_pred = encoder.transform(y_predict)
y_true_s = encoder.transform(y_test_s)
y_pred_s = encoder.transform(y_predict_s)

"""# without Straification"""

acc = accuracy_score(y_true,y_pred)
pre = precision_score(y_true,y_pred)
re = recall_score(y_true,y_pred)
f1 = f1_score(y_true,y_pred)
print('Accuracy: ',acc)
print('Precision: ',pre)
print('Recall: ',re)
print('f1-Score: ',f1)

"""# with Straification"""

acc = accuracy_score(y_true_s,y_pred_s)
pre = precision_score(y_true_s,y_pred_s)
re = recall_score(y_true_s,y_pred_s)
f1 = f1_score(y_true_s,y_pred_s)
print('Accuracy: ',acc)
print('Precision: ',pre)
print('Recall: ',re)
print('f1-Score: ',f1)