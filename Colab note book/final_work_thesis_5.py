# -*- coding: utf-8 -*-
"""final work thesis 5

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XCpj-VvOrWyix5X-2Pbobo8sxTbMLMQk

# free use
"""

from google.colab import drive
drive.mount('/content/drive')

"""# 1. anova_chi_test_n_500"""

import numpy as np
import pandas as pd
from sklearn.feature_selection import SelectKBest, chi2 , f_classif,f_regression,mutual_info_classif,mutual_info_regression
from sklearn.svm import SVR

"""# Getting the genes from anova and chi2"""

#cancerXgene list


cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD","READ","SARC","STAD","THCA","THYM","UCEC"]
normal_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD","READ","SARC","STAD","THCA","THYM","UCEC"]

#reading data and doing work
for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/package check/cancer/"+cancer_names[index]+".csv.gz", header=None, index_col=None)
  Normal = pd.read_csv("/content/drive/MyDrive/package check/normal/"+normal_names[index]+".norm.csv.gz", header=None, index_col=None) 

  #droping sample names needed man whats your problem?
  Cancer = Cancer.drop(Cancer.index[0])
  Cancer = Cancer.drop(columns=[0])
  Normal = Normal.drop(Normal.index[0])
  Normal = Normal.drop(columns=[0])

  #transpose
  Cancer_T = Cancer.T
  Normal_T = Normal.T
  #setting target
  Cancer_T["20501"] = 1.0
  Normal_T["20501"] = 0.0

  Cancer_T = Cancer_T.T
  Normal_T = Normal_T.T

  Cancer_T = Cancer_T.reset_index(drop=True)
  Normal_T = Normal_T.reset_index(drop=True)

  Cancer_T = Cancer_T.T
  Normal_T = Normal_T.T

  #print(Cancer_T)

  #dropping row
  Normal_T = Normal_T.drop(Normal_T.index[0])

  #concating
  X = pd.concat((Cancer_T,Normal_T),axis=0)
  # X = X.drop(columns = [0])
  # X = X.drop(X.index[0])
  x = X.iloc[:,:20501]
  y = X.iloc[:,20501]

  #print(x)
  #print(y)

  #selecting k value for anova
  k =  5

  #Anova test
  selector = SelectKBest(f_classif, k=k)
  selector.fit(x, y)
  cols_anova = selector.get_support(indices=True)
  np.save("/content/drive/MyDrive/capstone_work_part_2/std_npy/"+cancer_names[index],cols_anova)

"""# 2. Data Process

## Step 1
"""

import numpy as np
import pandas as pd
from sklearn.feature_selection import SelectKBest, chi2 , f_classif,f_regression,mutual_info_classif,mutual_info_regression
from sklearn.svm import SVR

"""# Frequency Check"""

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD","READ","SARC","STAD","THCA","THYM","UCEC"]

data = pd.read_csv("/content/drive/MyDrive/package check/cancer/CHOL.csv.gz",header=None)
one_col = data.iloc[:,0:1]
one_col = one_col.drop(one_col.index[0])

gene_frequency = []
#reading data and doing work
for index in range(len(cancer_names)):
  DATA = np.load("/content/drive/MyDrive/capstone_work_part_2/std_npy/"+cancer_names[index]+".npy")
  # print(DATA)
  # print(DATA[0])
  #print(len(DATA))
  for i in range(len(DATA)):
    if (DATA[i] != 0):
      gene_frequency.append(one_col[0][DATA[i]])

np.save("/content/drive/MyDrive/capstone_work_part_2/std_npy/gene_frequency",gene_frequency)

"""## Step 2"""

import numpy as np
import json
import operator
import pandas as pd

gene_freq_count_list = np.load("/content/drive/MyDrive/capstone_work_part_2/std_npy/gene_frequency.npy")
unique_elements, counts_elements = np.unique(gene_freq_count_list, return_counts=True)
print("Unique genes:",len(unique_elements))

top_gene = {}

for i in range(len(unique_elements)):
	top_gene[unique_elements[i]] = counts_elements[i]
sorted_top_gene = dict(sorted(top_gene.items(), key=lambda item: item[1],reverse=True))
import csv
with open('/content/drive/MyDrive/capstone_work_part_2/std_npy/gene_frequency.csv', 'w') as f:
    for key in sorted_top_gene.keys():
        f.write("%s,%d\n"%(key,sorted_top_gene[key]))


np.save("/content/drive/MyDrive/capstone_work_part_2/data/genes_that_willbe_filtered",unique_elements)
data = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/std_npy/gene_frequency.csv",header=None)
counts = data.groupby(1).count()
counts.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/std_npy/gene_frequency_across_cancer.csv',header=None,index=None,index_label=None)

"""## Step 3

"""

## 1. select_gene_name_based_on_h1 ##

import numpy as np
import pandas as pd
import csv
import random

# importing the unique m genes name
unique_genes = np.load("/content/drive/MyDrive/capstone_work_part_2/data/genes_that_willbe_filtered.npy")

# reading and making a dictonary of counted numbers of genes based on their frequency
with open('/content/drive/MyDrive/capstone_work_part_2/std_npy/gene_frequency.csv', mode='r') as infile:
    reader = csv.reader(infile)
    gene_freq_dict = {rows[0]:rows[1] for rows in reader}

# print(type(unique_genes))
# print(unique_genes.shape)
# print(len(unique_genes))
# for gense in unique_genes:
# 	print(gense)

selected_genes = []
genes_with_freq_one = []
genes_with_freq_two = []
genes_with_freq_three = []
for gene in unique_genes:
  # if(gene_freq_dict[gene] == "1"):
  #   genes_with_freq_one.append(gene)
  # elif(gene_freq_dict[gene] == "2"):
  #   genes_with_freq_two.append(gene)
  # elif(gene_freq_dict[gene] == "3"):
  #   genes_with_freq_three.append(gene)
  # else:
  #   selected_genes.append(gene)
  selected_genes.append(gene)
  
#selected_genes = selected_genes[0:round(((len(selected_genes)/100) * 24.22))]
# selected_genes = selected_genes + genes_with_freq_three[0:round(((len(genes_with_freq_three)/100) * 25))] #55% taken
# selected_genes = selected_genes + genes_with_freq_two[0:round(((len(genes_with_freq_two)/100) * 15))] #45% taken
# selected_genes = selected_genes + genes_with_freq_one[0:round(((len(genes_with_freq_one)/100) * 5))] #55% taken

np.save("/content/drive/MyDrive/capstone_work_part_2/data/selected_genes_h2", selected_genes)

print(len(selected_genes))

"""## Step 4"""

## 2. select_gene_need_to_drop_h1 ##

import numpy as np
import pandas as pd
import csv
import random

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD","READ","SARC","STAD","THCA","THYM","UCEC"]

selected_genes = np.load("/content/drive/MyDrive/capstone_work_part_2/data/selected_genes_h2.npy")
print(len(selected_genes))
data = pd.read_csv("/content/drive/MyDrive/package check/cancer/KICH.csv.gz",header=None)
header_gene_names =  data.iloc[:,0:1]
header_gene_names = header_gene_names.drop(header_gene_names.index[0])
header_gene_names.reset_index(drop=True, inplace=True)
# print(header_gene_names)
# print(header_gene_names.shape)

data_read = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/smoothed_cancer/KICHsmoothed.txt.bz2",header=None, delimiter = '\t')
# print(data_read)
#print(header_gene_names.shape)
#print(data_read.shape)

# adding gene names in a std cancer data

frame0 = [data_read,header_gene_names]
data_cancer_early = pd.concat(frame0, axis = 1)
data_cancer_early = data_cancer_early.T
data_cancer_early.reset_index(drop=True, inplace=True)


cols_exist = []
cols_to_del = []

#print(data_cancer_early)

# selecting the genes that we need from "selected genes"
for i in range(20501):
	for j in range(len(selected_genes)):
		if(data_cancer_early[i][91] == selected_genes[j]):
			cols_exist.append(i)

# selecting the genes that we need to drop from "cols_to_exist"
for i in range(20501):
	if(i not in cols_exist):
		cols_to_del.append(i)

print(len(cols_to_del))
# saving the genes that we need to drop
np.save("/content/drive/MyDrive/capstone_work_part_2/data/genes_to_del_500k_h2",cols_to_del)

"""## Step 5"""

## 3. save_data_after_gene_del_h2 ##

import numpy as np
import pandas as pd
import csv
import random
from sklearn.preprocessing import StandardScaler

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD","READ","SARC","STAD","THCA","THYM","UCEC"]

# loading the genes that need to delete and saving the data again after removing the deleted genes
selected_genes = np.load("/content/drive/MyDrive/capstone_work_part_2/data/genes_to_del_500k_h2.npy")
print(len(selected_genes))

for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/package check/smoothed_cancer/"+cancer_names[index]+"smoothed.txt.bz2",header=None, delimiter = '\t')
  Normal = pd.read_csv("/content/drive/MyDrive/package check/smoothed_normal/"+cancer_names[index]+"smoothed.txt.bz2",header=None, delimiter = '\t')

  Cancer = Cancer.T
  Normal = Normal.T

  cancer = Cancer.drop(columns = selected_genes)
  normal = Normal.drop(columns = selected_genes)

  print(cancer.shape)
  print(normal.shape)

  cancer = cancer.T
  normal = normal.T

  std_scaler_can = StandardScaler()
  std_scaler_norm = StandardScaler()

  cancer = pd.DataFrame(std_scaler_can.fit_transform(cancer), columns=cancer.columns)
  normal = pd.DataFrame(std_scaler_norm.fit_transform(normal), columns=normal.columns)

  cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/mahin/data_k_50/cancer/'+cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)
  normal.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/mahin/data_k_50/normal/'+cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""## test train split for cancer (manually)"""

#for cancer

import numpy as np
import pandas as pd
import csv
import random
from sklearn.preprocessing import StandardScaler

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD","READ","SARC","STAD","THCA","THYM","UCEC"]
#len(cancer_names)
for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/mahin/data_k_50/cancer/"+cancer_names[index]+".txt.bz2",header=None, delimiter = '\t')
  print(cancer_names[index])
  print(len(Cancer.columns))
  val_train = round((len(Cancer.columns) * 75) / 100) 
  val_test = len(Cancer.columns) - val_train
  print(val_train)
  print(val_test)
  print()
  i = 0

  cols_for_test = []
  cols_for_train = []

  while i < val_test:
    x = random.randint(0,(len(Cancer.columns)-1))
    if x not in cols_for_test:
      cols_for_test.append(x)
      i += 1
  i = 0
  while i < val_train:
    x = random.randint(0,(len(Cancer.columns)-1))
    if x not in cols_for_test:
      if x not in cols_for_train:
        cols_for_train.append(x)
        i += 1

  test_cancer = Cancer.drop(columns = cols_for_train)
  train_cancer = Cancer.drop(columns = cols_for_test)

  test_cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/cancer/'+cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)
  train_cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/pre_upsample_train_data/cancer/'+cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""## test train split for normal (manually)"""

#for normal

import numpy as np
import pandas as pd
import csv
import random
from sklearn.preprocessing import StandardScaler

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH",
                "KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD",
                "READ","SARC","STAD","THCA","THYM","UCEC"]
#len(cancer_names)
for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/mahin/data_k_50/normal/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = '\t')
  print(cancer_names[index])
  print(len(Cancer.columns))
  if(len(Cancer.columns) != 2):
    val_train = round((len(Cancer.columns) * 75) / 100) 
    val_test = len(Cancer.columns) - val_train
    print(val_train)
    print(val_test)
    print()
    i = 0

    cols_for_test = []
    cols_for_train = []

    while i < val_test:
      x = random.randint(0,(len(Cancer.columns)-1))
      if x not in cols_for_test:
        cols_for_test.append(x)
        i += 1
    i = 0
    while i < val_train:
      x = random.randint(0,(len(Cancer.columns)-1))
      if x not in cols_for_test:
        if x not in cols_for_train:
          cols_for_train.append(x)
          i += 1

    test_cancer = Cancer.drop(columns = cols_for_train)
    train_cancer = Cancer.drop(columns = cols_for_test)

    test_cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/normal/'+
                      cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)
    train_cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/pre_upsample_train_data/normal/'+
                        cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)

  else:
    val_train = 2
    val_test = 1
    print(val_train)
    print(val_test)
    print()
    cols_for_train = [1]
    test_cancer = Cancer.drop(columns = cols_for_train)
    train_cancer = Cancer

    test_cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/normal/'+
                  cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)
    train_cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/pre_upsample_train_data/normal/'+
                        cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""## upsampling train data set in 3:1



"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from collections import Counter

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH",
                "KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD",
                "READ","SARC","STAD","THCA","THYM","UCEC"]

#len(cancer_names)

for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/pre_upsample_train_data/cancer/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = '\t')
  Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/pre_upsample_train_data/normal/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = '\t')

  # print(Cancer)
  # print(Normal)
  can_sample = len(Cancer.columns)
  norm_sample = len(Normal.columns)
  print(cancer_names[index])
  print(can_sample)
  print(norm_sample)
  
  Cancer = Cancer.T
  Normal = Normal.T

  if( norm_sample <= round(can_sample/3) ):
    ## adding target in the last col
    Cancer['105'] = 1
    Normal['105'] = 0
    
    #print(Cancer)

    frame = [Cancer,Normal]
    Data = pd.concat(frame,axis=0)

    # print(Data)

    x = Data.iloc[:,:105]
    y = Data.iloc[:,105]
    # print(x)
    # print(y)

    # summarize class distribution
    counter = Counter(y)
    print(counter)
    # transform the dataset
    oversample = SMOTE(k_neighbors=1, sampling_strategy=0.3333)
    X, y = oversample.fit_resample(x, y)
    # summarize the new class distribution
    counter = Counter(y)
    print(counter)
    #[1:,1:],index=data[1:,0],columns=data[0,1:]
    X = pd.DataFrame(data=X)
    y = pd.DataFrame(data=y)

    data = pd.concat([X,y], axis = 1)
    data = data.T
    data = data.reset_index(drop=True)
    #print(data)
    #print(len(data.columns))
    can = []
    norm = []
    for x in range(len(data.columns)):
      if(data[x][105]==0):
        norm.append(x)
      elif(data[x][105]==1):
        can.append(x)

    drops_for_can = []

    for x in range(len(data.columns)):
      if(x not in can):
        drops_for_can.append(x)
    Cancer = data.drop(columns=drops_for_can)

    drops_for_norm = []

    for x in range(len(data.columns)):
      if(x not in norm):
        drops_for_norm.append(x)
    Normal = data.drop(columns=drops_for_norm)

    Cancer = Cancer.drop(Cancer.index[105])
    Normal = Normal.drop(Normal.index[105])

    # Cancer = Cancer.T
    # Normal = Normal.T

    #print(Cancer)

    Cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/train_data/cancer/'+
                  cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)
    Normal.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/train_data/normal/'+
                  cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""#TCGA bin data merging

## train
"""

## 4. merging_data_h1 ##

import numpy as np
import pandas as pd

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC",
                "KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD",
                "PCPG","PRAD","READ","SARC","STAD","THCA","THYM",
                "UCEC"]

#reading data and doing work
cresult=pd.DataFrame()
nresult=pd.DataFrame()
for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/cancer/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = "\t")
  Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/normal/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = "\t")
  
  Cancer= Cancer.T
  Normal=Normal.T
  
  frames1 = [Cancer, cresult]
  cresult = pd.concat(frames1)
  
  frames2 = [Normal, nresult]
  nresult = pd.concat(frames2)
  
  print(cresult.shape)
  print(nresult.shape)
  
# merging all the cancer and normal data together and saving them  
cresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/train_data/bin_Cancer_5.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

nresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/train_data/bin_Normal_5.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""## test"""

## 4. merging_data_h1 ##

import numpy as np
import pandas as pd

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC",
                "KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD",
                "PCPG","PRAD","READ","SARC","STAD","THCA","THYM",
                "UCEC"]

#reading data and doing work
cresult=pd.DataFrame()
nresult=pd.DataFrame()
for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/cancer/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = "\t")
  Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/normal/"+
                      cancer_names[index]+".txt.bz2",header=None, delimiter = "\t")
  
  Cancer= Cancer.T
  Normal=Normal.T
  
  frames1 = [Cancer, cresult]
  cresult = pd.concat(frames1)
  
  frames2 = [Normal, nresult]
  nresult = pd.concat(frames2)
  
  print(cresult.shape)
  print(nresult.shape)
  
# merging all the cancer and normal data together and saving them  
cresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/bin_Cancer_5.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

nresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/bin_Normal_5.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""# tcga pan data merging

## train
"""

## HYPOTHESIS 1 ##

import numpy as np
import pandas as pd
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC",
                "KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD",
                "PCPG","PRAD","READ","SARC","STAD","THCA","THYM",
                "UCEC"]


#reading data and doing work
cresult=pd.DataFrame()
nresult=pd.DataFrame()
print(len(cancer_names))
#len(cancer_names)
for index in range(2):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/cancer/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = "\t")
  Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/normal/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = "\t")

  Cancer = Cancer.T
  Normal = Normal.T
  #print(Cancer)
  #print(Normal)

  Cancer['target'] = cancer_names[index]
  Normal['target'] = "normal"

  frames1 = [Cancer, cresult]
  cresult = pd.concat(frames1)
  
  frames2 = [Normal, nresult]
  nresult = pd.concat(frames2)
  
  print(cresult.shape)
  print(nresult.shape)
  

# merging all the cancer and normal data together separately and saving them  
cresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Cancer_5.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

nresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Normal_5.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""## test"""

## HYPOTHESIS 1 ##

import numpy as np
import pandas as pd
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC",
                "KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD",
                "PCPG","PRAD","READ","SARC","STAD","THCA","THYM",
                "UCEC"]


#reading data and doing work
cresult=pd.DataFrame()
nresult=pd.DataFrame()
print(len(cancer_names))
#len(cancer_names)
for index in range(2):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/cancer/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = "\t")
  Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/normal/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = "\t")

  Cancer = Cancer.T
  Normal = Normal.T
  #print(Cancer)
  #print(Normal)

  Cancer['target'] = cancer_names[index]
  Normal['target'] = "normal"

  frames1 = [Cancer, cresult]
  cresult = pd.concat(frames1)
  
  frames2 = [Normal, nresult]
  nresult = pd.concat(frames2)
  
  print(cresult.shape)
  print(nresult.shape)
  

# merging all the cancer and normal data together separately and saving them  
cresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Cancer_5.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

nresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Normal_5.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""# Model train, validation

## Plot function
"""

import matplotlib.pyplot as plt

def plot_confusion_matrix(y_true, y_pred,
                          normalize=False,
                          title=None,
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if not title:
        if normalize:
            title = 'Normalized confusion matrix'
        else:
            title = 'Confusion matrix, without normalization'

    # Compute confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    print(cm)

    fig, ax = plt.subplots()
    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)
    ax.figure.colorbar(im, ax=ax)
    # We want to show all ticks...
    ax.set(xticks=np.arange(cm.shape[1]),
           yticks=np.arange(cm.shape[0]),
           # ... and label them with the respective list entries
           title=title,
           ylabel='True label',
           xlabel='Predicted label')

    # Rotate the tick labels and set their alignment.
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right",
             rotation_mode="anchor")

    # Loop over data dimensions and create text annotations.
    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, format(cm[i, j], fmt),
                    ha="center", va="center",
                    color="white" if cm[i, j] > thresh else "black")
    fig.tight_layout()
    return ax

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report
import pandas as pd 
import seaborn as sns
def heatconmat(y_true,y_pred):
  sns.set_context('talk')
  df = pd.Series(y_true)
  plt.figure(figsize=(18,12))
  sns.heatmap(confusion_matrix(df,y_pred),
              annot=True,
              fmt='d',
              cbar=False,
              cmap='gist_earth_r',
              yticklabels=sorted(df.unique()))
  plt.show()
  print(classification_report(df,y_pred))

"""## KNN"""

## upsampling + kNN ##

# Oversample and plot imbalanced dataset with SMOTE
import io
import numpy as np
import pandas as pd
import pylab as pl
from scipy import interp
from sklearn import tree
from sklearn.svm import SVC
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
from sklearn.utils.multiclass import unique_labels
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
from numpy import where

#train data load
Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/bin_Cancer_5.txt.bz2",header=None, delimiter = "\t")
Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/bin_Normal_5.txt.bz2",header=None, delimiter = "\t")
Cancer['Target'] = 1
Normal['Target'] = 0
#Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
X_train = Data.iloc[:,:105]
y_train = Data.iloc[:,105]

#test data load
Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/bin_Cancer_5.txt.bz2",header=None, delimiter = "\t")
Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/bin_Normal_5.txt.bz2",header=None, delimiter = "\t")
Cancer['Target'] = 1
Normal['Target'] = 0
#Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
X_test = Data.iloc[:,:105]
y_test = Data.iloc[:,105]

k_vals = [1,2,3,4,5,6]

for i in k_vals:
  print(f"---------(kNN with k value {i})-----------")
  neigh = KNeighborsClassifier(n_neighbors=i)
  neigh.fit(X_train, y_train)
  y_pred = neigh.predict(X_test)

  plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')
  plt.show()
  #print(confusion_matrix(y_test,y_pred))
  print(classification_report(y_test,y_pred))
  print(f"MCC Score (kNN with k value {i}): ",matthews_corrcoef(y_test, y_pred))
  print(f"---------(kNN with k value {i})-----------")
  print()

"""## KNN multiclass"""

## upsampling + kNN ##

# Oversample and plot imbalanced dataset with SMOTE
import io
import numpy as np
import pandas as pd
import pylab as pl
from scipy import interp
from sklearn import tree
from sklearn.svm import SVC
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
from sklearn.utils.multiclass import unique_labels
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
from numpy import where

#train load
Cancer = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Cancer_5.txt.bz2",
    header=None, delimiter = "\t")
Normal = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Normal_5.txt.bz2",
    header=None, delimiter = "\t")
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
#print(Data)
X_train = Data.iloc[:,:105]
y_train = Data.iloc[:,105]
# print(x)
# print(Y)

#test load
Cancer = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Cancer_5.txt.bz2",
    header=None, delimiter = "\t")
Normal = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Normal_5.txt.bz2",
    header=None, delimiter = "\t")
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
#print(Data)
X_test = Data.iloc[:,:105]
y_test = Data.iloc[:,105]
# print(x)
# print(Y)

k_vals = [1,2,3,4]

for i in k_vals:
  print(f"---------(kNN with k value {i})-----------")
  neigh = KNeighborsClassifier(n_neighbors=i)
  neigh.fit(X_train, y_train)
  y_pred = neigh.predict(X_test)

  heatconmat(y_test, y_pred)
  #print(confusion_matrix(y_test,y_pred))
  #print(classification_report(y_test,y_pred))
  print(f"MCC Score (kNN with k value {i}): ",matthews_corrcoef(y_test, y_pred))
  print(f"---------(kNN with k value {i})-----------")
  print()

"""## Random Forest"""

## upsampling + RF ##

# Oversample and plot imbalanced dataset with SMOTE
import io
import numpy as np
import pandas as pd
import pylab as pl
from scipy import interp
from sklearn import tree
from sklearn.svm import SVC
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
from sklearn.utils.multiclass import unique_labels
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
from collections import Counter
from numpy import where

#train data load
Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/bin_Cancer_5.txt.bz2",header=None, delimiter = "\t")
Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/bin_Normal_5.txt.bz2",header=None, delimiter = "\t")
Cancer['Target'] = 1
Normal['Target'] = 0
#Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
X_train = Data.iloc[:,:105]
y_train = Data.iloc[:,105]

#test data load
Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/bin_Cancer_5.txt.bz2",header=None, delimiter = "\t")
Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/bin_Normal_5.txt.bz2",header=None, delimiter = "\t")
Cancer['Target'] = 1
Normal['Target'] = 0
#Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
X_test = Data.iloc[:,:105]
y_test = Data.iloc[:,105]

print("---------(RF BASIC)-----------")
clf = RandomForestClassifier(n_estimators=100)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')
plt.show()
#print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print("MCC Score (RF BASIC): ",matthews_corrcoef(y_test, y_pred))
# print("---------(RF BASIC)-----------")

"""## Random Forest multiclass"""

## upsampling + RF ##

# Oversample and plot imbalanced dataset with SMOTE
import io
import numpy as np
import pandas as pd
import pylab as pl
from scipy import interp
from sklearn import tree
from sklearn.svm import SVC
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
from sklearn.utils.multiclass import unique_labels
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
from collections import Counter
from numpy import where

#train load
Cancer = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Cancer_5.txt.bz2",
    header=None, delimiter = "\t")
Normal = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Normal_5.txt.bz2",
    header=None, delimiter = "\t")
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
#print(Data)
X_train = Data.iloc[:,:105]
y_train = Data.iloc[:,105]
# print(x)
# print(Y)

#test load
Cancer = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Cancer_5.txt.bz2",
    header=None, delimiter = "\t")
Normal = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Normal_5.txt.bz2",
    header=None, delimiter = "\t")
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
#print(Data)
X_test = Data.iloc[:,:105]
y_test = Data.iloc[:,105]
# print(x)
# print(Y)

print("---------(RF BASIC)-----------")
clf = RandomForestClassifier(n_estimators=100)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
heatconmat(y_test, y_pred)
# plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')
# plt.show()
#print(confusion_matrix(y_test,y_pred))
#print(classification_report(y_test,y_pred))
print("MCC Score (RF BASIC): ",matthews_corrcoef(y_test, y_pred))
# print("---------(RF BASIC)-----------")

"""## Kernel SVM (Linear & RBF)"""

## upsampling + SVM ##

# Oversample and plot imbalanced dataset with SMOTE
import io
import numpy as np
import pandas as pd
import pylab as pl
from scipy import interp
from sklearn import tree
from sklearn.svm import SVC
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
from numpy import where
import joblib

#train data load
Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/bin_Cancer_5.txt.bz2",header=None, delimiter = "\t")
Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/bin_Normal_5.txt.bz2",header=None, delimiter = "\t")
Cancer['Target'] = 1
Normal['Target'] = 0
#Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
X_train = Data.iloc[:,:105]
y_train = Data.iloc[:,105]

#test data load
Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/bin_Cancer_5.txt.bz2",header=None, delimiter = "\t")
Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/bin_Normal_5.txt.bz2",header=None, delimiter = "\t")
Cancer['Target'] = 1
Normal['Target'] = 0
#Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
X_test = Data.iloc[:,:105]
y_test = Data.iloc[:,105]

svclassifier = SVC(kernel='linear', C=1)
svclassifier.fit(X_train, y_train)

y_pred = svclassifier.predict(X_test)

print("---------(linear Kernel)-----------")
plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')
plt.show()
#print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print("MCC Score (linear Kernel): ",matthews_corrcoef(y_test, y_pred))
print("---------(linear Kernel)-----------")


print("---------(RBF Kernel)-----------")
svclassifier = SVC(kernel='rbf', C=1)
svclassifier.fit(X_train, y_train)
y_pred = svclassifier.predict(X_test)

plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')
plt.show()

#print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print("MCC Score (RBF Kernel): ",matthews_corrcoef(y_test, y_pred))
print("---------(RBF Kernel)-----------")

"""## Kernel SVM (Linear & RBF) multiclass"""

## upsampling + SVM ##

# Oversample and plot imbalanced dataset with SMOTE
import io
import numpy as np
import pandas as pd
import pylab as pl
from scipy import interp
from sklearn import tree
from sklearn.svm import SVC
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
from numpy import where
import joblib

#train load
Cancer = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Cancer_5.txt.bz2",
    header=None, delimiter = "\t")
Normal = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Normal_5.txt.bz2",
    header=None, delimiter = "\t")
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
#print(Data)
X_train = Data.iloc[:,:105]
y_train = Data.iloc[:,105]
# print(x)
# print(Y)

#test load
Cancer = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Cancer_5.txt.bz2",
    header=None, delimiter = "\t")
Normal = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Normal_5.txt.bz2",
    header=None, delimiter = "\t")
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
#print(Data)
X_test = Data.iloc[:,:105]
y_test = Data.iloc[:,105]
# print(x)
# print(Y)

svclassifier = SVC(kernel='linear', C=1)
svclassifier.fit(X_train, y_train)

y_pred = svclassifier.predict(X_test)

print("---------(linear Kernel)-----------")
# plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')
# plt.show()
# #print(confusion_matrix(y_test,y_pred))
# print(classification_report(y_test,y_pred))
heatconmat(y_test, y_pred)
print("MCC Score (linear Kernel): ",matthews_corrcoef(y_test, y_pred))
print("---------(linear Kernel)-----------")


print("---------(RBF Kernel)-----------")
svclassifier = SVC(kernel='rbf', C=1)
svclassifier.fit(X_train, y_train)
y_pred = svclassifier.predict(X_test)
heatconmat(y_test, y_pred)
# plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')
# plt.show()

# #print(confusion_matrix(y_test,y_pred))
# print(classification_report(y_test,y_pred))
print("MCC Score (RBF Kernel): ",matthews_corrcoef(y_test, y_pred))
print("---------(RBF Kernel)-----------")

"""## Adaboost

"""

## upsampling + Adaboost ##

# Oversample and plot imbalanced dataset with SMOTE
import io
import numpy as np
import pandas as pd
import pylab as pl
from scipy import interp
from sklearn import tree
from sklearn.svm import SVC
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
from numpy import where
import joblib


#train data load
Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/bin_Cancer_5.txt.bz2",header=None, delimiter = "\t")
Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/bin_Normal_5.txt.bz2",header=None, delimiter = "\t")
Cancer['Target'] = 1
Normal['Target'] = 0
#Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
X_train = Data.iloc[:,:105]
y_train = Data.iloc[:,105]

#test data load
Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/bin_Cancer_5.txt.bz2",header=None, delimiter = "\t")
Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/bin_Normal_5.txt.bz2",header=None, delimiter = "\t")
Cancer['Target'] = 1
Normal['Target'] = 0
#Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
X_test = Data.iloc[:,:105]
y_test = Data.iloc[:,105]

adbcls = AdaBoostClassifier(n_estimators=50)
adbcls.fit(X_train, y_train)

y_pred = adbcls.predict(X_test)

print("---------(Adaboost)-----------")
plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')
plt.show()
#print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print("MCC Score (Adaboost): ",matthews_corrcoef(y_test, y_pred))
print("---------(Adaboost)-----------")

"""## Adaboost multiclass

"""

## upsampling + SVM ##

# Oversample and plot imbalanced dataset with SMOTE
import io
import numpy as np
import pandas as pd
import pylab as pl
from scipy import interp
from sklearn import tree
from sklearn.svm import SVC
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
from numpy import where
import joblib

#train load
Cancer = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Cancer_5.txt.bz2",
    header=None, delimiter = "\t")
Normal = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Normal_5.txt.bz2",
    header=None, delimiter = "\t")
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
#print(Data)
X_train = Data.iloc[:,:105]
y_train = Data.iloc[:,105]
# print(x)
# print(Y)

#test load
Cancer = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Cancer_5.txt.bz2",
    header=None, delimiter = "\t")
Normal = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Normal_5.txt.bz2",
    header=None, delimiter = "\t")
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
#print(Data)
X_test = Data.iloc[:,:105]
y_test = Data.iloc[:,105]
# print(Y)

adbcls = AdaBoostClassifier(n_estimators=50)
adbcls.fit(X_train, y_train)

y_pred = adbcls.predict(X_test)

print("---------(Adaboost)-----------")
# plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')
# plt.show()
# #print(confusion_matrix(y_test,y_pred))
# print(classification_report(y_test,y_pred))
heatconmat(y_test, y_pred)
print("MCC Score (Adaboost): ",matthews_corrcoef(y_test, y_pred))
print("---------(Adaboost)-----------")

"""## Neural network binary classifier"""

## upsampling + NN + binary ##

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from imblearn.over_sampling import SMOTE
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from collections import Counter
from sklearn.metrics import matthews_corrcoef
from keras.models import Sequential
from keras.layers import Dense

#train data load
Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/bin_Cancer_5.txt.bz2",header=None, delimiter = "\t")
Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/bin_Normal_5.txt.bz2",header=None, delimiter = "\t")
Cancer['Target'] = 1
Normal['Target'] = 0
#Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
X_train = Data.iloc[:,:105]
y_train = Data.iloc[:,105]

#test data load
Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/bin_Cancer_5.txt.bz2",header=None, delimiter = "\t")
Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/bin_Normal_5.txt.bz2",header=None, delimiter = "\t")
Cancer['Target'] = 1
Normal['Target'] = 0
#Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
X_test = Data.iloc[:,:105]
y_test = Data.iloc[:,105]


# define the keras model
model = Sequential()
model.add(Dense(1024, input_dim=105, activation='relu'))
model.add(Dense(512, activation='relu'))
model.add(Dense(256, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
# compile the keras model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
# fit the keras model on the dataset
model.fit(X_train, y_train, epochs=100, batch_size=100)

y_pred = model.predict_classes(X_test)

y_pred_seris = pd.Series(y_pred.flatten())


print("---------(Neural Network)-----------")
plot_confusion_matrix(y_test, y_pred_seris, title='Confusion matrix, without normalization')
plt.show()
#print(confusion_matrix(y_test,y_pred_seris))
print(classification_report(y_test,y_pred_seris))
print("MCC Score (Neural Network): ",matthews_corrcoef(y_test, y_pred_seris))
print("---------(Neural Network)-----------")

model.save("/content/drive/MyDrive/capstone_work_part_2/nn_bin_tcga.h5")

"""## Neural network multiclass classification"""

## upsampling + NN + multiclass ##

from imblearn.over_sampling import SMOTE
from collections import Counter
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from keras.utils import np_utils
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline

#train load
Cancer = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Cancer_5.txt.bz2",
    header=None, delimiter = "\t")
Normal = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Normal_5.txt.bz2",
    header=None, delimiter = "\t")
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
#print(Data)
X_train = Data.iloc[:,:105]
y_train = Data.iloc[:,105]
# print(x)
# print(Y)

#test load
Cancer = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Cancer_5.txt.bz2",
    header=None, delimiter = "\t")
Normal = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Normal_5.txt.bz2",
    header=None, delimiter = "\t")
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
#print(Data)
X_test = Data.iloc[:,:105]
y_test = Data.iloc[:,105]
# print(x)
# print(Y)

# encode class values as integers
encoder = LabelEncoder()
encoder.fit(y_train)
encoded_Y = encoder.transform(y_train)
# convert integers to dummy variables (i.e. one hot encoded)
y_train = np_utils.to_categorical(encoded_Y)

encoder = LabelEncoder()
encoder.fit(y_test)
y_test = encoder.transform(y_test)

# define baseline model
model = Sequential()
model.add(Dense(1024, input_dim=105, activation='relu'))
model.add(Dense(512, activation='relu'))
model.add(Dense(256, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(23, activation='softmax'))
# compile the keras model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
# fit the keras model on the dataset
model.fit(X_train, y_train, epochs=100, batch_size=100)

#y_train = np_utils.to_categorical(y_train)

y_pred = model.predict_classes(X_test)

#y_test_flat = [np.where(r==1)[0][0] for r in y_test]

print("---------(Neural Network)-----------")
# plot_confusion_matrix(y_test_flat, y_pred, title='Confusion matrix, without normalization')
# plt.show()
heatconmat(y_test, y_pred)
#print(confusion_matrix(y_test_flat,y_pred))
#print(classification_report(y_test_flat,y_pred))
print("MCC Score (Neural Network): ",matthews_corrcoef(y_test, y_pred))
print("---------(Neural Network)-----------")

model.save("/content/drive/MyDrive/capstone_work_part_2/nn_pan_tcga.h5")

"""# Test set data process

"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from keras.utils import np_utils
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.feature_selection import SelectKBest, chi2 , f_classif,f_regression,mutual_info_classif,mutual_info_regression
from sklearn.svm import SVR

brca_can_s = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/cancer_brcaSmoothed.txt.bz2",header=None, delimiter = "\t")
brca_norm_s = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/normal_brcaSmoothed.txt.bz2",header=None, delimiter = "\t")
brca_can = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/cancer_brca.txt.bz2",header=None, delimiter = "\t")
brca_norm = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/normal_brca.txt.bz2",header=None, delimiter = "\t")

# brca_can = brca_can.T
# brca_norm = brca_norm.T

brca_can_s = brca_can_s.T
brca_norm_s = brca_norm_s.T

#Merge BRCA
brca_can['target'] = 1
brca_norm['target'] = 0

brca_can = brca_can.drop(brca_can.index[0])
brca_norm = brca_norm.drop(brca_norm.index[0])
print(brca_can)
print(brca_norm)
frames = [brca_can,brca_norm]
df_brca = pd.concat(frames,axis=0)
#df_brca

brca_can_s = brca_can_s.drop(brca_can_s.index[0])
brca_norm_s = brca_norm_s.drop(brca_norm_s.index[0])
# print(brca_can)
# print(brca_norm)
frames = [brca_can_s,brca_norm_s]
df_brca_s = pd.concat(frames,axis=0)
df_brca_s = df_brca.reset_index(drop=True)

#df_brca = df_brca.drop(df_brca.index[0])
df_brca = df_brca.reset_index(drop=True)
df_brca_s = df_brca_s.reset_index(drop=True)
#df_brca

x_brca = df_brca.iloc[:,:57914]
y_brca = df_brca.iloc[:,57914]
#y_brca

k=105
#Anova test
selector = SelectKBest(f_classif, k=k)
selector.fit(x_brca, y_brca)
cols_anova = selector.get_support(indices=True)

cols_to_del = []
for i in range(57914):
    if(i not in cols_anova):
        cols_to_del.append(i)

df_brca_s = df_brca_s.drop(columns=cols_to_del)
# frames = [df_brca_s,y_brca]
# brca_data = pd.concat(frames,axis=1)

df_brca_s = df_brca_s.T 
df_brca_s = df_brca_s.reset_index(drop=True)
print(df_brca_s)

can = []
norm = []
for x in range(513):
  if(df_brca_s[x][k]==0.0):
    norm.append(x)
  elif(df_brca_s[x][k]==1.0):
    can.append(x)

drops_for_can = []

for x in range(513):
  if(x not in can):
    drops_for_can.append(x)
cancer_brca = df_brca_s.drop(columns=drops_for_can)
#cancer_brca

drops_for_norm = []

for x in range(513):
  if(x not in norm):
    drops_for_norm.append(x)
normal_brca = df_brca_s.drop(columns=drops_for_norm)
#normal_brca

normal_brca = normal_brca.T
cancer_brca = cancer_brca.T
normal_brca = normal_brca.reset_index(drop=True)

print(normal_brca)
print(cancer_brca)

skcm_can_s = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/cancer_skcmSmoothed.txt.bz2",header=None, delimiter = "\t")
skcm_norm_s = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/normal_skcmSmoothed.txt.bz2",header=None, delimiter = "\t")
skcm_can = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/cancer_skcm.txt.bz2",header=None, delimiter = "\t")
skcm_norm = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/normal_skcm.txt.bz2",header=None, delimiter = "\t")

# skcm_can = skcm_can.T
# skcm_norm = skcm_norm.T

skcm_can_s = skcm_can_s.T
skcm_norm_s = skcm_norm_s.T

#Merge skcm
skcm_can['target'] = 1
skcm_norm['target'] = 0

skcm_can = skcm_can.drop(skcm_can.index[0])
skcm_norm = skcm_norm.drop(skcm_norm.index[0])
print(skcm_can)
print(skcm_norm)
frames = [skcm_can,skcm_norm]
df_skcm = pd.concat(frames,axis=0)
#df_skcm

skcm_can_s = skcm_can_s.drop(skcm_can_s.index[0])
skcm_norm_s = skcm_norm_s.drop(skcm_norm_s.index[0])
# print(skcm_can)
# print(skcm_norm)
frames = [skcm_can_s,skcm_norm_s]
df_skcm_s = pd.concat(frames,axis=0)
df_skcm_s = df_skcm.reset_index(drop=True)

#df_skcm = df_skcm.drop(df_skcm.index[0])
df_skcm = df_skcm.reset_index(drop=True)
df_skcm_s = df_skcm_s.reset_index(drop=True)
#df_skcm

x_skcm = df_skcm.iloc[:,:23686]
y_skcm = df_skcm.iloc[:,23686]
#y_skcm


#Anova test
selector = SelectKBest(f_classif, k=k)
selector.fit(x_skcm, y_skcm)
cols_anova = selector.get_support(indices=True)

cols_to_del = []
for i in range(23686):
    if(i not in cols_anova):
        cols_to_del.append(i)

df_skcm_s = df_skcm_s.drop(columns=cols_to_del)
# frames = [df_skcm_s,y_skcm]
# skcm_data = pd.concat(frames,axis=1)

df_skcm_s = df_skcm_s.T 
df_skcm_s = df_skcm_s.reset_index(drop=True)
print(df_skcm_s)

can = []
norm = []
for x in range(4511):
  if(df_skcm_s[x][k]==0.0):
    norm.append(x)
  elif(df_skcm_s[x][k]==1.0):
    can.append(x)

drops_for_can = []

for x in range(4511):
  if(x not in can):
    drops_for_can.append(x)
cancer_skcm = df_skcm_s.drop(columns=drops_for_can)
#cancer_skcm

drops_for_norm = []

for x in range(4511):
  if(x not in norm):
    drops_for_norm.append(x)
normal_skcm = df_skcm_s.drop(columns=drops_for_norm)
#normal_skcm

normal_skcm = normal_skcm.T
cancer_skcm = cancer_skcm.T
normal_skcm = normal_skcm.reset_index(drop=True)

print(normal_skcm)
print(cancer_skcm)

cancer_brca = cancer_brca.drop(columns=[k])
normal_brca = normal_brca.drop(columns=[k])
cancer_skcm = cancer_skcm.drop(columns=[k])
normal_skcm = normal_skcm.drop(columns=[k])
print(cancer_brca)

from sklearn.preprocessing import StandardScaler

frames = [cancer_brca,cancer_skcm]
cancer_bin = pd.concat(frames,axis=0)
#print(cancer_bin)
frames = [normal_brca,normal_skcm]
normal_bin = pd.concat(frames,axis=0)
#print(normal_bin)

# create a scaler object
std_scaler_can = StandardScaler()
std_scaler_norm = StandardScaler()
# fit and transform the data
df_std_can_bin = pd.DataFrame(std_scaler_can.fit_transform(cancer_bin), columns=cancer_bin.columns)
df_std_norm_bin = pd.DataFrame(std_scaler_norm.fit_transform(normal_bin), columns=normal_bin.columns)
print(df_std_can_bin)

df_std_can_bin.to_csv(r"/content/drive/MyDrive/capstone_works/TEST DATA/std_cancer_bin"+str(k)+".txt.bz2",compression="bz2", sep='\t',header=None,index=None,index_label=None)
df_std_norm_bin.to_csv(r"/content/drive/MyDrive/capstone_works/TEST DATA/std_normal_bin"+str(k)+".txt.bz2",compression="bz2", sep='\t',header=None,index=None,index_label=None)

#print(cancer_brca)

std_scaler_can_brca = StandardScaler()
std_scaler_norm_brca = StandardScaler()
std_scaler_can_skcm = StandardScaler()
std_scaler_norm_skcm = StandardScaler()
# fit and transform the data
df_std_can_pan_brca = pd.DataFrame(std_scaler_can_brca.fit_transform(cancer_brca), columns=cancer_brca.columns)
df_std_norm_pan_brca = pd.DataFrame(std_scaler_norm_brca.fit_transform(normal_brca), columns=normal_brca.columns)
df_std_can_pan_skcm = pd.DataFrame(std_scaler_can_skcm.fit_transform(cancer_skcm), columns=cancer_skcm.columns)
df_std_norm_pan_skcm = pd.DataFrame(std_scaler_norm_skcm.fit_transform(normal_skcm), columns=normal_skcm.columns)

df_std_can_pan_brca['target'] = 'brca'
df_std_norm_pan_brca['target'] = 'norm'
df_std_can_pan_skcm['target'] = 'skcm'
df_std_norm_pan_skcm['target'] = 'norm'

frames = [df_std_can_pan_brca, df_std_can_pan_skcm, df_std_norm_pan_brca, df_std_norm_pan_skcm]
can_norm_pan = pd.concat(frames,axis=0) 
#can_norm_pan

can_norm_pan.to_csv(r"/content/drive/MyDrive/capstone_works/TEST DATA/std_can_norm_pan"+str(k)+".txt.bz2",compression="bz2", sep='\t',header=None,index=None,index_label=None)

# frames = [df_std_can_pan_brca, df_std_can_pan_skcm, df_std_norm_pan_brca, df_std_norm_pan_skcm]
# can_norm_pan = pd.concat(frames,axis=0) 
# #can_norm_pan

# can_norm_pan.to_csv(r"/content/drive/MyDrive/capstone_works/TEST DATA/std_can_norm_pan.txt.bz2",compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""# Test work = bin + multi

## Plot function
"""

import matplotlib.pyplot as plt

def plot_confusion_matrix(y_true, y_pred,
                          normalize=False,
                          title=None,
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if not title:
        if normalize:
            title = 'Normalized confusion matrix'
        else:
            title = 'Confusion matrix, without normalization'

    # Compute confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    print(cm)

    fig, ax = plt.subplots()
    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)
    ax.figure.colorbar(im, ax=ax)
    # We want to show all ticks...
    ax.set(xticks=np.arange(cm.shape[1]),
           yticks=np.arange(cm.shape[0]),
           # ... and label them with the respective list entries
           title=title,
           ylabel='True label',
           xlabel='Predicted label')

    # Rotate the tick labels and set their alignment.
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right",
             rotation_mode="anchor")

    # Loop over data dimensions and create text annotations.
    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, format(cm[i, j], fmt),
                    ha="center", va="center",
                    color="white" if cm[i, j] > thresh else "black")
    fig.tight_layout()
    return ax

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report
import pandas as pd 
import seaborn as sns
def heatconmat(y_true,y_pred):
  sns.set_context('talk')
  df = pd.Series(y_true)
  plt.figure(figsize=(18,12))
  sns.heatmap(confusion_matrix(df,y_pred),
              annot=True,
              fmt='d',
              cbar=False,
              cmap='gist_earth_r',
              yticklabels=sorted(df.unique()))
  plt.show()
  print(classification_report(df,y_pred))

"""## KNN"""

## upsampling + kNN ##

# Oversample and plot imbalanced dataset with SMOTE
import io
import numpy as np
import pandas as pd
import pylab as pl
from scipy import interp
from sklearn import tree
from sklearn.svm import SVC
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
from sklearn.utils.multiclass import unique_labels
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
from numpy import where

Cancer = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/std_cancer_bin"+str(k)+".txt.bz2",header=None, delimiter = "\t")
Normal = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/std_normal_bin"+str(k)+".txt.bz2",header=None, delimiter = "\t")
#print(Cancer)
#print(Normal)
Cancer['Target'] = 1
Normal['Target'] = 0
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
x = Data.iloc[:,:k]
y = Data.iloc[:,k]
#print(x.shape)
#print(y.shape)



X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)

k_vals = [1,2,3,4,5,6]

for i in k_vals:
  print(f"---------(kNN with k value {i})-----------")
  neigh = KNeighborsClassifier(n_neighbors=i)
  neigh.fit(X_train, y_train)
  y_pred = neigh.predict(X_test)

  plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')
  plt.show()
  #print(confusion_matrix(y_test,y_pred))
  print(classification_report(y_test,y_pred))
  print(f"MCC Score (kNN with k value {i}): ",matthews_corrcoef(y_test, y_pred))
  print(f"---------(kNN with k value {i})-----------")
  print()

"""## KNN multiclass"""

## upsampling + kNN ##

# Oversample and plot imbalanced dataset with SMOTE
import io
import numpy as np
import pandas as pd
import pylab as pl
from scipy import interp
from sklearn import tree
from sklearn.svm import SVC
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
from sklearn.utils.multiclass import unique_labels
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
from numpy import where


# define dataset
# x, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,
# 	n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)


Data = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/std_can_norm_pan"+str(k)+".txt.bz2",header=None, delimiter = "\t")
x = Data.iloc[:,:k]
Y = Data.iloc[:,k]

# # encode class values as integers
# encoder = LabelEncoder()
# encoder.fit(Y)
# encoded_Y = encoder.transform(Y)
# # convert integers to dummy variables (i.e. one hot encoded)
# dummy_y = np_utils.to_categorical(encoded_Y)

X_train, X_test, y_train, y_test = train_test_split(x, Y, test_size = 0.25)
# # summarize class distribution
# counter = Counter(y_train)
# print(counter)
# # transform the dataset
# oversample = SMOTE()
# X_train_new, y_train_new = oversample.fit_resample(X_train, y_train)
# # summarize the new class distribution
# counter = Counter(y_train_new)
# print(counter)

k_vals = [1,2,3,4,5,6,7,8,9]

for i in k_vals:
  print(f"---------(kNN with k value {i})-----------")
  neigh = KNeighborsClassifier(n_neighbors=i)
  neigh.fit(X_train, y_train)
  y_pred = neigh.predict(X_test)

  plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')
  plt.show()
  #print(confusion_matrix(y_test,y_pred))
  print(classification_report(y_test,y_pred))
  print(f"MCC Score (kNN with k value {i}): ",matthews_corrcoef(y_test, y_pred))
  print(f"---------(kNN with k value {i})-----------")
  print()

"""## Random Forest"""

## upsampling + RF ##

# Oversample and plot imbalanced dataset with SMOTE
import io
import numpy as np
import pandas as pd
import pylab as pl
from scipy import interp
from sklearn import tree
from sklearn.svm import SVC
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
from sklearn.utils.multiclass import unique_labels
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
from collections import Counter
from numpy import where

Cancer = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/std_cancer_bin"+str(k)+".txt.bz2",header=None, delimiter = "\t")
Normal = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/std_normal_bin"+str(k)+".txt.bz2",header=None, delimiter = "\t")
#print(Cancer)
#print(Normal)
Cancer['Target'] = 1
Normal['Target'] = 0
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
x = Data.iloc[:,:k]
y = Data.iloc[:,k]
#print(x.shape)
#print(y.shape)



X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)

print("---------(RF BASIC)-----------")
clf = RandomForestClassifier(n_estimators=100)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')
plt.show()
#print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print("MCC Score (RF BASIC): ",matthews_corrcoef(y_test, y_pred))
# print("---------(RF BASIC)-----------")

"""## Random Forest multiclass"""

## upsampling + RF ##

# Oversample and plot imbalanced dataset with SMOTE
import io
import numpy as np
import pandas as pd
import pylab as pl
from scipy import interp
from sklearn import tree
from sklearn.svm import SVC
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
from sklearn.utils.multiclass import unique_labels
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
from collections import Counter
from numpy import where


# define dataset
# x, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,
# 	n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)


Data = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/std_can_norm_pan"+str(k)+".txt.bz2",header=None, delimiter = "\t")
x = Data.iloc[:,:k]
Y = Data.iloc[:,k]

# # encode class values as integers
# encoder = LabelEncoder()
# encoder.fit(Y)
# encoded_Y = encoder.transform(Y)
# # convert integers to dummy variables (i.e. one hot encoded)
# dummy_y = np_utils.to_categorical(encoded_Y)

X_train, X_test, y_train, y_test = train_test_split(x, Y, test_size = 0.25)
#print(X_train.shape)
#print(X_test.shape)

# # summarize class distribution
# counter = Counter(y_train)
# print(counter)
# # transform the dataset
# oversample = SMOTE()
# X_train_new, y_train_new = oversample.fit_resample(X_train, y_train)
# # summarize the new class distribution
# counter = Counter(y_train_new)
# print(counter)

print("---------(RF BASIC)-----------")
clf = RandomForestClassifier(n_estimators=100)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')
plt.show()
#print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print("MCC Score (RF BASIC): ",matthews_corrcoef(y_test, y_pred))
# print("---------(RF BASIC)-----------")

# print("---------(RF n_es = 50, min_im = 0.05)-----------")
# clf = RandomForestClassifier(n_estimators=100, min_impurity_decrease=0.05)
# clf.fit(X_train, y_train)
# y_pred = clf.predict(X_test)

# plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')
# plt.show()
# #print(confusion_matrix(y_test,y_pred))
# print(classification_report(y_test,y_pred))
# print("MCC Score (RF n_es = 50, min_im = 0.05): ",matthews_corrcoef(y_test, y_pred))
# print("---------(RF n_es = 50, min_im = 0.05)-----------")

"""## Kernel SVM (Linear & RBF)"""

## upsampling + SVM ##

# Oversample and plot imbalanced dataset with SMOTE
import io
import numpy as np
import pandas as pd
import pylab as pl
from scipy import interp
from sklearn import tree
from sklearn.svm import SVC
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
from numpy import where
import joblib

Cancer = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/std_cancer_bin"+str(k)+".txt.bz2",header=None, delimiter = "\t")
Normal = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/std_normal_bin"+str(k)+".txt.bz2",header=None, delimiter = "\t")
#print(Cancer)
#print(Normal)
Cancer['Target'] = 1
Normal['Target'] = 0
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
x = Data.iloc[:,:k]
y = Data.iloc[:,k]
#print(x.shape)
#print(y.shape)



X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)

svclassifier = SVC(kernel='linear', C=1)
svclassifier.fit(X_train, y_train)

y_pred = svclassifier.predict(X_test)

print("---------(linear Kernel)-----------")
plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')
plt.show()
#print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print("MCC Score (linear Kernel): ",matthews_corrcoef(y_test, y_pred))
print("---------(linear Kernel)-----------")


print("---------(RBF Kernel)-----------")
svclassifier = SVC(kernel='rbf', C=1)
svclassifier.fit(X_train, y_train)
y_pred = svclassifier.predict(X_test)

plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')
plt.show()

#print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print("MCC Score (RBF Kernel): ",matthews_corrcoef(y_test, y_pred))
print("---------(RBF Kernel)-----------")

"""## SVM kernels (Linear & RBF) multiclass"""

import io
import numpy as np
import pandas as pd
import pylab as pl
from scipy import interp
from sklearn import tree
from sklearn.svm import SVC
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
from sklearn.utils.multiclass import unique_labels
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
from numpy import where
Data = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/std_can_norm_pan"+str(k)+".txt.bz2",header=None, delimiter = "\t")
x = Data.iloc[:,:k]
Y = Data.iloc[:,k]

# # encode class values as integers
# encoder = LabelEncoder()
# encoder.fit(Y)
# encoded_Y = encoder.transform(Y)
# # convert integers to dummy variables (i.e. one hot encoded)
# dummy_y = np_utils.to_categorical(encoded_Y)

X_train, X_test, y_train, y_test = train_test_split(x, Y, test_size = 0.25)

# # summarize class distribution
# counter = Counter(y_train)
# print(counter)
# # transform the dataset
# oversample = SMOTE()
# X_train_new, y_train_new = oversample.fit_resample(X_train, y_train)
# # summarize the new class distribution
# counter = Counter(y_train_new)
# print(counter)
# #print(X.shape())

svclassifier = SVC(kernel='linear', C=1)
svclassifier.fit(X_train, y_train)

y_pred = svclassifier.predict(X_test)

print("---------(linear Kernel)-----------")
# plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')
# plt.show()
# #print(confusion_matrix(y_test,y_pred))
# print(classification_report(y_test,y_pred))
heatconmat(y_test, y_pred)
print("MCC Score (linear Kernel): ",matthews_corrcoef(y_test, y_pred))
print("---------(linear Kernel)-----------")


print("---------(RBF Kernel)-----------")
svclassifier = SVC(kernel='rbf', C=1)
svclassifier.fit(X_train, y_train)
y_pred = svclassifier.predict(X_test)
heatconmat(y_test, y_pred)
# plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')
# plt.show()

# #print(confusion_matrix(y_test,y_pred))
# print(classification_report(y_test,y_pred))
print("MCC Score (RBF Kernel): ",matthews_corrcoef(y_test, y_pred))
print("---------(RBF Kernel)-----------")

"""## Adaboost

"""

## upsampling + Adaboost ##

# Oversample and plot imbalanced dataset with SMOTE
import io
import numpy as np
import pandas as pd
import pylab as pl
from scipy import interp
from sklearn import tree
from sklearn.svm import SVC
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
from numpy import where
import joblib


Cancer = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/std_cancer_bin"+str(k)+".txt.bz2",header=None, delimiter = "\t")
Normal = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/std_normal_bin"+str(k)+".txt.bz2",header=None, delimiter = "\t")
#print(Cancer)
#print(Normal)
Cancer['Target'] = 1
Normal['Target'] = 0
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
x = Data.iloc[:,:k]
y = Data.iloc[:,k]
#print(x.shape)
#print(y.shape)



X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)

adbcls = AdaBoostClassifier(n_estimators=50)
adbcls.fit(X_train, y_train)

y_pred = adbcls.predict(X_test)

print("---------(Adaboost)-----------")
plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')
plt.show()
#print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print("MCC Score (Adaboost): ",matthews_corrcoef(y_test, y_pred))
print("---------(Adaboost)-----------")

"""## Adaboost multiclass

"""

## upsampling + SVM ##

# Oversample and plot imbalanced dataset with SMOTE
import io
import numpy as np
import pandas as pd
import pylab as pl
from scipy import interp
from sklearn import tree
from sklearn.svm import SVC
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
from numpy import where
import joblib

#train load
Data = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/std_can_norm_pan"+str(k)+".txt.bz2",header=None, delimiter = "\t")
x = Data.iloc[:,:k]
Y = Data.iloc[:,k]

# # encode class values as integers
# encoder = LabelEncoder()
# encoder.fit(Y)
# encoded_Y = encoder.transform(Y)
# # convert integers to dummy variables (i.e. one hot encoded)
# dummy_y = np_utils.to_categorical(encoded_Y)

X_train, X_test, y_train, y_test = train_test_split(x, Y, test_size = 0.25)

adbcls = AdaBoostClassifier(n_estimators=50)
adbcls.fit(X_train, y_train)

y_pred = adbcls.predict(X_test)

print("---------(Adaboost)-----------")
# plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')
# plt.show()
# #print(confusion_matrix(y_test,y_pred))
# print(classification_report(y_test,y_pred))
heatconmat(y_test, y_pred)
print("MCC Score (Adaboost): ",matthews_corrcoef(y_test, y_pred))
print("---------(Adaboost)-----------")

"""## Neural Network multiclass """

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from keras.utils import np_utils
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline
Data = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/std_can_norm_pan"+str(k)+".txt.bz2",header=None, delimiter = "\t")
x = Data.iloc[:,:k]
Y = Data.iloc[:,k]

# # encode class values as integers
# encoder = LabelEncoder()
# encoder.fit(Y)
# encoded_Y = encoder.transform(Y)
# # convert integers to dummy variables (i.e. one hot encoded)
# dummy_y = np_utils.to_categorical(encoded_Y)


# encode class values as integers
encoder = LabelEncoder()
encoder.fit(Y)
encoded_Y = encoder.transform(Y)
# convert integers to dummy variables (i.e. one hot encoded)
dummy_y = np_utils.to_categorical(encoded_Y)

X_train, X_test, y_train, y_test = train_test_split(x, dummy_y, test_size = 0.25)
class myCallback(tf.keras.callbacks.Callback): 
    def on_epoch_end(self, epoch, logs={}): 
        if(logs.get('loss') < 0.05):   
          #print("\nWe have reached %2.2f%% accuracy, so we will stopping training." %(0.99*100))   
          self.model.stop_training = True
# define baseline model
def baseline_model():
	# create model
  model = Sequential()
  model.add(Dense(1024, input_dim=k, activation='relu'))
  model.add(Dense(512, activation='relu'))
  model.add(Dense(256, activation='relu'))
  model.add(Dense(128, activation='relu'))
  model.add(Dense(64, activation='relu'))
  model.add(Dense(32, activation='relu'))
  model.add(Dense(3, activation='softmax'))
	# Compile model
  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
  return model
callbacks = myCallback()
model = baseline_model()
#model.fit(X_train, y_train, epochs=35, batch_size=100 , callbacks=[callbacks], verbose=1)
model.fit(X_train, y_train, epochs=100, batch_size=100)

y_pred = model.predict_classes(X_test)

y_test_flat = [np.where(r==1)[0][0] for r in y_test]

print("---------(Neural Network)-----------")
#print(confusion_matrix(y_test_flat,y_pred))
#print(classification_report(y_test_flat,y_pred))
heatconmat(y_test_flat, y_pred)
print("MCC Score (Neural Network): ",matthews_corrcoef(y_test_flat, y_pred))
print("---------(Neural Network)-----------")

"""## Neural Network binary"""

import io
import numpy as np
import pandas as pd
import pylab as pl
from scipy import interp
from sklearn import tree
from sklearn.svm import SVC
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
from sklearn.utils.multiclass import unique_labels
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
from numpy import where
Cancer = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/std_cancer_bin"+str(k)+".txt.bz2",header=None, delimiter = "\t")
Normal = pd.read_csv("/content/drive/MyDrive/capstone_works/TEST DATA/std_normal_bin"+str(k)+".txt.bz2",header=None, delimiter = "\t")
#print(Cancer)
#print(Normal)
Cancer['Target'] = 1
Normal['Target'] = 0
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
x = Data.iloc[:,:k]
y = Data.iloc[:,k]
#print(x.shape)
#print(y.shape)



X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)

# # summarize class distribution
# counter = Counter(y_train)
# print(counter)
# # transform the dataset
# oversample = SMOTE()
# X_train_new, y_train_new = oversample.fit_resample(X_train, y_train)
# # summarize the new class distribution
# counter = Counter(y_train_new)
# print(counter)
# #print(X.shape())

# define the keras model
model = Sequential()
model.add(Dense(1024, input_dim=k, activation='relu'))
model.add(Dense(512, activation='relu'))
model.add(Dense(256, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
# compile the keras model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
# fit the keras model on the dataset
model.fit(X_train, y_train, epochs=100, batch_size=100)

y_pred = model.predict_classes(X_test)

y_pred_seris = pd.Series(y_pred.flatten())


print("---------(Neural Network)-----------")
print(confusion_matrix(y_test,y_pred_seris))
print(classification_report(y_test,y_pred_seris))
print("MCC Score (Neural Network): ",matthews_corrcoef(y_test, y_pred_seris))
print("---------(Neural Network)-----------")