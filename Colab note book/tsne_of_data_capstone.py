# -*- coding: utf-8 -*-
"""TSNE of data capstone.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SNA-BA6gRkBP5NV6zUs-SX0WzeZrFUGj
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
from __future__ import print_function
import time
import numpy as np
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
# %matplotlib inline
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import seaborn as sns
## upsampling + NN + multiclass ##

from imblearn.over_sampling import SMOTE
from collections import Counter
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from keras.utils import np_utils
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline

k = 5
gene_con = 105

"""# 1. anova_chi_test_n_500"""

import numpy as np
import pandas as pd
from sklearn.feature_selection import SelectKBest, chi2 , f_classif,f_regression,mutual_info_classif,mutual_info_regression
from sklearn.svm import SVR

"""# Getting the genes from anova and chi2"""

#cancerXgene list


cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD","READ","SARC","STAD","THCA","THYM","UCEC"]
normal_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD","READ","SARC","STAD","THCA","THYM","UCEC"]

#reading data and doing work
for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/package check/cancer/"+cancer_names[index]+".csv.gz", header=None, index_col=None)
  Normal = pd.read_csv("/content/drive/MyDrive/package check/normal/"+normal_names[index]+".norm.csv.gz", header=None, index_col=None) 

  #droping sample names needed man whats your problem?
  Cancer = Cancer.drop(Cancer.index[0])
  Cancer = Cancer.drop(columns=[0])
  Normal = Normal.drop(Normal.index[0])
  Normal = Normal.drop(columns=[0])

  # Cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/cancer_wo_h/'+
  #               cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)
  # Normal.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/normal_wo_h/'+
  #               cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)

  #transpose
  Cancer_T = Cancer.T
  Normal_T = Normal.T

  #setting target
  Cancer_T["20501"] = 1.0
  Normal_T["20501"] = 0.0

  Cancer_T = Cancer_T.T
  Normal_T = Normal_T.T

  Cancer_T = Cancer_T.reset_index(drop=True)
  Normal_T = Normal_T.reset_index(drop=True)

  Cancer_T = Cancer_T.T
  Normal_T = Normal_T.T

  #print(Cancer_T)

  #dropping row
  Normal_T = Normal_T.drop(Normal_T.index[0])

  #concating
  X = pd.concat((Cancer_T,Normal_T),axis=0)
  # X = X.drop(columns = [0])
  # X = X.drop(X.index[0])
  x = X.iloc[:,:20501]
  y = X.iloc[:,20501]

  #print(x)
  #print(y)

  #selecting k value for anova
  k = 5

  #Anova test
  selector = SelectKBest(f_classif, k=k)
  selector.fit(x, y)
  cols_anova = selector.get_support(indices=True)
  np.save("/content/drive/MyDrive/capstone_work_part_2/std_npy/"+cancer_names[index],cols_anova)

"""# 2. Data Process

## Step 1
"""

import numpy as np
import pandas as pd
from sklearn.feature_selection import SelectKBest, chi2 , f_classif,f_regression,mutual_info_classif,mutual_info_regression
from sklearn.svm import SVR

"""# Frequency Check"""

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD","READ","SARC","STAD","THCA","THYM","UCEC"]

data = pd.read_csv("/content/drive/MyDrive/package check/cancer/CHOL.csv.gz",header=None)
one_col = data.iloc[:,0:1]
one_col = one_col.drop(one_col.index[0])

gene_frequency = []
#reading data and doing work
for index in range(len(cancer_names)):
  DATA = np.load("/content/drive/MyDrive/capstone_work_part_2/std_npy/"+cancer_names[index]+".npy")
  # print(DATA)
  # print(DATA[0])
  #print(len(DATA))
  for i in range(len(DATA)):
    if (DATA[i] != 0):
      gene_frequency.append(one_col[0][DATA[i]])

np.save("/content/drive/MyDrive/capstone_work_part_2/std_npy/gene_frequency",gene_frequency)

"""## Step 2"""

import numpy as np
import json
import operator
import pandas as pd

gene_freq_count_list = np.load("/content/drive/MyDrive/capstone_work_part_2/std_npy/gene_frequency.npy")
unique_elements, counts_elements = np.unique(gene_freq_count_list, return_counts=True)
print("Unique genes:",len(unique_elements))

top_gene = {}

for i in range(len(unique_elements)):
	top_gene[unique_elements[i]] = counts_elements[i]
sorted_top_gene = dict(sorted(top_gene.items(), key=lambda item: item[1],reverse=True))
import csv
with open('/content/drive/MyDrive/capstone_work_part_2/std_npy/gene_frequency.csv', 'w') as f:
    for key in sorted_top_gene.keys():
        f.write("%s,%d\n"%(key,sorted_top_gene[key]))


np.save("/content/drive/MyDrive/capstone_work_part_2/data/genes_that_willbe_filtered",unique_elements)
data = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/std_npy/gene_frequency.csv",header=None)
counts = data.groupby(1).count()
counts.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/std_npy/gene_frequency_across_cancer.csv',header=None,index=None,index_label=None)

"""## Step 3

"""

## 1. select_gene_name_based_on_h1 ##

import numpy as np
import pandas as pd
import csv
import random

# importing the unique m genes name
unique_genes = np.load("/content/drive/MyDrive/capstone_work_part_2/data/genes_that_willbe_filtered.npy")

# reading and making a dictonary of counted numbers of genes based on their frequency
with open('/content/drive/MyDrive/capstone_work_part_2/std_npy/gene_frequency.csv', mode='r') as infile:
    reader = csv.reader(infile)
    gene_freq_dict = {rows[0]:rows[1] for rows in reader}

# print(type(unique_genes))
# print(unique_genes.shape)
# print(len(unique_genes))
# for gense in unique_genes:
# 	print(gense)

selected_genes = []
genes_with_freq_one = []
genes_with_freq_two = []
genes_with_freq_three = []
for gene in unique_genes:
  # if(gene_freq_dict[gene] == "1"):
  #   genes_with_freq_one.append(gene)
  # elif(gene_freq_dict[gene] == "2"):
  #   genes_with_freq_two.append(gene)
  # elif(gene_freq_dict[gene] == "3"):
  #   genes_with_freq_three.append(gene)
  # else:
  #   selected_genes.append(gene)
  selected_genes.append(gene)
  
#selected_genes = selected_genes[0:round(((len(selected_genes)/100) * 24.22))]
# selected_genes = selected_genes + genes_with_freq_three[0:round(((len(genes_with_freq_three)/100) * 25))] #55% taken
# selected_genes = selected_genes + genes_with_freq_two[0:round(((len(genes_with_freq_two)/100) * 15))] #45% taken
# selected_genes = selected_genes + genes_with_freq_one[0:round(((len(genes_with_freq_one)/100) * 5))] #55% taken

np.save("/content/drive/MyDrive/capstone_work_part_2/data/selected_genes_h2", selected_genes)

print(len(selected_genes))

gene_con = len(selected_genes)

"""## Step 4"""

## 2. select_gene_need_to_drop_h1 ##

import numpy as np
import pandas as pd
import csv
import random

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD","READ","SARC","STAD","THCA","THYM","UCEC"]

selected_genes = np.load("/content/drive/MyDrive/capstone_work_part_2/data/selected_genes_h2.npy")
print(len(selected_genes))
data = pd.read_csv("/content/drive/MyDrive/package check/cancer/KICH.csv.gz",header=None)
header_gene_names =  data.iloc[:,0:1]
header_gene_names = header_gene_names.drop(header_gene_names.index[0])
header_gene_names.reset_index(drop=True, inplace=True)
# print(header_gene_names)
# print(header_gene_names.shape)

data_read = pd.read_csv(r"/content/drive/MyDrive/capstone_work_part_2/smoothed_cancer/KICHsmoothed.txt.bz2",header=None, delimiter = '\t')
# print(data_read)
#print(header_gene_names.shape)
#print(data_read.shape)

# adding gene names in a std cancer data

frame0 = [data_read,header_gene_names]
data_cancer_early = pd.concat(frame0, axis = 1)
data_cancer_early = data_cancer_early.T
data_cancer_early.reset_index(drop=True, inplace=True)


cols_exist = []
cols_to_del = []

#print(data_cancer_early)

# selecting the genes that we need from "selected genes"
for i in range(20501):
	for j in range(len(selected_genes)):
		if(data_cancer_early[i][91] == selected_genes[j]):
			cols_exist.append(i)

# selecting the genes that we need to drop from "cols_to_exist"
for i in range(20501):
	if(i not in cols_exist):
		cols_to_del.append(i)

print(len(cols_to_del))
# saving the genes that we need to drop
np.save("/content/drive/MyDrive/capstone_work_part_2/data/genes_to_del_500k_h2",cols_to_del)

"""## Step 5"""

## 3. save_data_after_gene_del_h2 ##

import numpy as np
import pandas as pd
import csv
import random
from sklearn.preprocessing import StandardScaler

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD","READ","SARC","STAD","THCA","THYM","UCEC"]

# loading the genes that need to delete and saving the data again after removing the deleted genes
selected_genes = np.load("/content/drive/MyDrive/capstone_work_part_2/data/genes_to_del_500k_h2.npy")
print(len(selected_genes))

for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/smoothed_cancer/"+
                       cancer_names[index]+"smoothed.txt.bz2",header=None, delimiter = '\t')
  Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/smoothed_normal/"+
                       cancer_names[index]+"smoothed.txt.bz2",header=None, delimiter = '\t')

  Cancer = Cancer.T
  Normal = Normal.T

  cancer = Cancer.drop(columns = selected_genes)
  normal = Normal.drop(columns = selected_genes)

  print(cancer.shape)
  print(normal.shape)

  cancer = cancer.T
  normal = normal.T

  std_scaler_can = StandardScaler()
  std_scaler_norm = StandardScaler()

  cancer = pd.DataFrame(std_scaler_can.fit_transform(cancer), columns=cancer.columns)
  normal = pd.DataFrame(std_scaler_norm.fit_transform(normal), columns=normal.columns)

  cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/mahin/data_k_50/cancer/'+cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)
  normal.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/mahin/data_k_50/normal/'+cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""## test train split for cancer (manually)"""

#for cancer

import numpy as np
import pandas as pd
import csv
import random
from sklearn.preprocessing import StandardScaler

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD","READ","SARC","STAD","THCA","THYM","UCEC"]
#len(cancer_names)
for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/mahin/data_k_50/cancer/"+cancer_names[index]+".txt.bz2",header=None, delimiter = '\t')
  print(cancer_names[index])
  print(len(Cancer.columns))
  val_train = round((len(Cancer.columns) * 75) / 100) 
  val_test = len(Cancer.columns) - val_train
  print(val_train)
  print(val_test)
  print()
  i = 0

  cols_for_test = []
  cols_for_train = []

  while i < val_test:
    x = random.randint(0,(len(Cancer.columns)-1))
    if x not in cols_for_test:
      cols_for_test.append(x)
      i += 1
  i = 0
  while i < val_train:
    x = random.randint(0,(len(Cancer.columns)-1))
    if x not in cols_for_test:
      if x not in cols_for_train:
        cols_for_train.append(x)
        i += 1

  test_cancer = Cancer.drop(columns = cols_for_train)
  train_cancer = Cancer.drop(columns = cols_for_test)

  test_cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/cancer/'+cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)
  train_cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/pre_upsample_train_data/cancer/'+cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""## test train split for normal (manually)"""

#for normal

import numpy as np
import pandas as pd
import csv
import random
from sklearn.preprocessing import StandardScaler

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH",
                "KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD",
                "READ","SARC","STAD","THCA","THYM","UCEC"]
#len(cancer_names)
for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/mahin/data_k_50/normal/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = '\t')
  print(cancer_names[index])
  print(len(Cancer.columns))
  if(len(Cancer.columns) != 2):
    val_train = round((len(Cancer.columns) * 75) / 100) 
    val_test = len(Cancer.columns) - val_train
    print(val_train)
    print(val_test)
    print()
    i = 0

    cols_for_test = []
    cols_for_train = []

    while i < val_test:
      x = random.randint(0,(len(Cancer.columns)-1))
      if x not in cols_for_test:
        cols_for_test.append(x)
        i += 1
    i = 0
    while i < val_train:
      x = random.randint(0,(len(Cancer.columns)-1))
      if x not in cols_for_test:
        if x not in cols_for_train:
          cols_for_train.append(x)
          i += 1

    test_cancer = Cancer.drop(columns = cols_for_train)
    train_cancer = Cancer.drop(columns = cols_for_test)

    test_cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/normal/'+
                      cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)
    train_cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/pre_upsample_train_data/normal/'+
                        cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)

  else:
    val_train = 2
    val_test = 1
    print(val_train)
    print(val_test)
    print()
    cols_for_train = [1]
    test_cancer = Cancer.drop(columns = cols_for_train)
    train_cancer = Cancer

    test_cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/normal/'+
                  cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)
    train_cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/pre_upsample_train_data/normal/'+
                        cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""## upsampling train data set in 3:1



"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from collections import Counter

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH",
                "KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD",
                "READ","SARC","STAD","THCA","THYM","UCEC"]

#len(cancer_names)

for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/pre_upsample_train_data/cancer/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = '\t')
  Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/pre_upsample_train_data/normal/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = '\t')

  # print(Cancer)
  # print(Normal)
  can_sample = len(Cancer.columns)
  norm_sample = len(Normal.columns)

  # print(can_sample)
  # print(norm_sample)
  
  Cancer = Cancer.T
  Normal = Normal.T

  if( norm_sample <= round(can_sample/3) ):
    ## adding target in the last col
    Cancer[str(gene_con)] = 1
    Normal[str(gene_con)] = 0
    
    #print(Cancer)

    frame = [Cancer,Normal]
    Data = pd.concat(frame,axis=0)

    #print(Data)

    x = Data.iloc[:,:gene_con]
    y = Data.iloc[:,gene_con]
    #print(x)
    #print(y)

    # summarize class distribution
    counter = Counter(y)
    print(counter)
    # transform the dataset
    oversample = SMOTE(k_neighbors=1, sampling_strategy=0.3333)
    X, y = oversample.fit_resample(x, y)
    # summarize the new class distribution
    counter = Counter(y)
    print(counter)
    #[1:,1:],index=data[1:,0],columns=data[0,1:]
    X = pd.DataFrame(data=X)
    y = pd.DataFrame(data=y)

    data = pd.concat([X,y], axis = 1)
    data = data.T
    data = data.reset_index(drop=True)
    #print(data)
    #print(len(data.columns))
    can = []
    norm = []
    for x in range(len(data.columns)):
      if(data[x][gene_con]==0):
        norm.append(x)
      elif(data[x][gene_con]==1):
        can.append(x)

    drops_for_can = []

    for x in range(len(data.columns)):
      if(x not in can):
        drops_for_can.append(x)
    Cancer = data.drop(columns=drops_for_can)

    drops_for_norm = []

    for x in range(len(data.columns)):
      if(x not in norm):
        drops_for_norm.append(x)
    Normal = data.drop(columns=drops_for_norm)

    Cancer = Cancer.drop(Cancer.index[gene_con])
    Normal = Normal.drop(Normal.index[gene_con])

    # Cancer = Cancer.T
    # Normal = Normal.T

    #print(Cancer)

    Cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/train_data/cancer/'+
                  cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)
    Normal.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/train_data/normal/'+
                  cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""## merging bin train data"""

## 4. merging_data_h1 ##

import numpy as np
import pandas as pd

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC",
                "KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD",
                "PCPG","PRAD","READ","SARC","STAD","THCA","THYM",
                "UCEC"]

#reading data and doing work
cresult=pd.DataFrame()
nresult=pd.DataFrame()
for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/cancer/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = "\t")
  Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/normal/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = "\t")
  
  Cancer= Cancer.T
  Normal=Normal.T
  
  frames1 = [Cancer, cresult]
  cresult = pd.concat(frames1)
  
  frames2 = [Normal, nresult]
  nresult = pd.concat(frames2)
  
  print(cresult.shape)
  print(nresult.shape)
  
# merging all the cancer and normal data together and saving them  
cresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/train_data/bin_Cancer_'+str(k)+'.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

nresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/train_data/bin_Normal_'+str(k)+'.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""## merging bin test data"""

## 4. merging_data_h1 ##

import numpy as np
import pandas as pd

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC",
                "KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD",
                "PCPG","PRAD","READ","SARC","STAD","THCA","THYM",
                "UCEC"]

#reading data and doing work
cresult=pd.DataFrame()
nresult=pd.DataFrame()
for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/cancer/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = "\t")
  Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/normal/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = "\t")
  
  Cancer= Cancer.T
  Normal=Normal.T
  
  frames1 = [Cancer, cresult]
  cresult = pd.concat(frames1)
  
  frames2 = [Normal, nresult]
  nresult = pd.concat(frames2)
  
  print(cresult.shape)
  print(nresult.shape)
  
# merging all the cancer and normal data together and saving them  
cresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/bin_Cancer_'+str(k)+'.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

nresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/bin_Normal_'+str(k)+'.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""# tcga pan data merging

## train
"""

## HYPOTHESIS 1 ##

import numpy as np
import pandas as pd
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC",
                "KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD",
                "PCPG","PRAD","READ","SARC","STAD","THCA","THYM",
                "UCEC"]


#reading data and doing work
cresult=pd.DataFrame()
nresult=pd.DataFrame()
print(len(cancer_names))
for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/cancer/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = "\t")
  Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/normal/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = "\t")

  Cancer = Cancer.T
  Normal = Normal.T
  #print(Cancer)
  #print(Normal)

  Cancer['target'] = cancer_names[index]
  Normal['target'] = "normal"

  frames1 = [Cancer, cresult]
  cresult = pd.concat(frames1)
  
  frames2 = [Normal, nresult]
  nresult = pd.concat(frames2)
  
  print(cresult.shape)
  print(nresult.shape)
  

# merging all the cancer and normal data together separately and saving them  
cresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Cancer_'+str(k)+'.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

nresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Normal_'+str(k)+'.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""## test"""

## HYPOTHESIS 1 ##

import numpy as np
import pandas as pd
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC",
                "KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD",
                "PCPG","PRAD","READ","SARC","STAD","THCA","THYM",
                "UCEC"]


#reading data and doing work
cresult=pd.DataFrame()
nresult=pd.DataFrame()
print(len(cancer_names))
for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/cancer/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = "\t")
  Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/normal/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = "\t")

  Cancer = Cancer.T
  Normal = Normal.T
  #print(Cancer)
  #print(Normal)

  Cancer['target'] = cancer_names[index]
  Normal['target'] = "normal"

  frames1 = [Cancer, cresult]
  cresult = pd.concat(frames1)
  
  frames2 = [Normal, nresult]
  nresult = pd.concat(frames2)
  
  print(cresult.shape)
  print(nresult.shape)
  

# merging all the cancer and normal data together separately and saving them  
cresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Cancer_'+str(k)+'.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

nresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Normal_'+str(k)+'.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""# TSNE

## Load Data test
"""

#test load
Cancer = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Cancer_"+str(k)+".txt.bz2",
    header=None, delimiter = "\t")
Normal = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Normal_"+str(k)+".txt.bz2",
    header=None, delimiter = "\t")
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
#print(Data)
X_train = Data.iloc[:,:gene_con]
y_train = Data.iloc[:,gene_con]

print(X_train.shape)
print(y_train.shape)

encoder = LabelEncoder()
encoder.fit(y_train)
encoded_Y = encoder.transform(y_train)
print(type(encoded_Y))

X_train['y'] = encoded_Y
np.random.seed(42)
rndperm = np.random.permutation(Data.shape[0])

pca = PCA(n_components=3)
pca_result = pca.fit_transform(X_train)
X_train['pca-one'] = pca_result[:,0]
X_train['pca-two'] = pca_result[:,1] 
X_train['pca-three'] = pca_result[:,2]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))

plt.figure(figsize=(16,10))
sns.scatterplot(
    x="pca-one", y="pca-two",
    hue="y",
    #palette=sns.color_palette('bright', X_train.y.unique().shape[0]),
    # palette = sns.color_palette('bright', 23),
    palette = sns.color_palette('husl', X_train.y.unique().shape[0]),
    data=X_train,
    legend="full",
    alpha=1
)

ax = plt.figure(figsize=(16,10)).gca(projection='3d')
ax.scatter(
    xs=X_train.iloc[rndperm,:]["pca-one"], 
    ys=X_train.iloc[rndperm,:]["pca-two"], 
    zs=X_train.iloc[rndperm,:]["pca-three"], 
    c=X_train.iloc[rndperm,:]["y"], 
    cmap='tab10'
)
ax.set_xlabel('pca-one')
ax.set_ylabel('pca-two')
ax.set_zlabel('pca-three')
plt.show()

import plotly.express as px
fig = px.scatter_3d(X_train, x='pca-one', y='pca-two', z='pca-three',color='y')
fig.show()

"""tsne

"""

Cancer = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Cancer_"+str(k)+".txt.bz2",
    header=None, delimiter = "\t")
Normal = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Normal_"+str(k)+".txt.bz2",
    header=None, delimiter = "\t")
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
#print(Data)
X_train = Data.iloc[:,:gene_con]
y_train = Data.iloc[:,gene_con]

print(X_train.shape)
print(y_train.shape)

import numpy as np
from sklearn.datasets import load_digits
from scipy.spatial.distance import pdist
from sklearn.manifold.t_sne import _joint_probabilities
from scipy import linalg
from sklearn.metrics import pairwise_distances
from scipy.spatial.distance import squareform
from sklearn.manifold import TSNE
from matplotlib import pyplot as plt
import seaborn as sns

sns.set(rc={'figure.figsize':(11.7,8.27)})
palette = sns.color_palette("flare", 23)

tsne = TSNE()
X_embedded = tsne.fit_transform(X_train)
sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y_train, legend='full', palette=palette)

"""## Load Data Train  (Ei purata for smoothed)


"""

#train load
Cancer = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Cancer_"+str(k)+".txt.bz2",
    header=None, delimiter = "\t")
Normal = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Normal_"+str(k)+".txt.bz2",
    header=None, delimiter = "\t")
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
#print(Data)
X_train = Data.iloc[:,:gene_con]
y_train = Data.iloc[:,gene_con]

print(X_train.shape)
print(y_train.shape)

encoder = LabelEncoder()
encoder.fit(y_train)
encoded_Y = encoder.transform(y_train)
print(type(encoded_Y))

X_train['y'] = encoded_Y
np.random.seed(42)
rndperm = np.random.permutation(Data.shape[0])

pca = PCA(n_components=3)
pca_result = pca.fit_transform(X_train)
X_train['pca-one'] = pca_result[:,0]
X_train['pca-two'] = pca_result[:,1] 
X_train['pca-three'] = pca_result[:,2]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))

plt.figure(figsize=(16,10))
sns.scatterplot(
    x="pca-one", y="pca-two",
    hue="y",
    #palette=sns.color_palette('bright', X_train.y.unique().shape[0]),
    # palette = sns.color_palette('bright', 23),
    palette = sns.color_palette('husl', X_train.y.unique().shape[0]),
    data=X_train,
    legend="full",
    alpha=1
)

ax = plt.figure(figsize=(16,10)).gca(projection='3d')
ax.scatter(
    xs=X_train.iloc[rndperm,:]["pca-one"], 
    ys=X_train.iloc[rndperm,:]["pca-two"], 
    zs=X_train.iloc[rndperm,:]["pca-three"], 
    c=X_train.iloc[rndperm,:]["y"], 
    cmap='tab10'
)
ax.set_xlabel('pca-one')
ax.set_ylabel('pca-two')
ax.set_zlabel('pca-three')
plt.show()

import plotly.express as px
fig = px.scatter_3d(X_train, x='pca-one', y='pca-two', z='pca-three',color='y')
fig.show()

"""tsne

"""

Cancer = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Cancer_"+str(k)+".txt.bz2",
    header=None, delimiter = "\t")
Normal = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Normal_"+str(k)+".txt.bz2",
    header=None, delimiter = "\t")
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
#print(Data)
X_train = Data.iloc[:,:gene_con]
y_train = Data.iloc[:,gene_con]

print(X_train.shape)
print(y_train.shape)

# #Eta color eksthe input nite 
# colors = []
# temp = input()
# colors = temp.split(" ")
# colors
X_train.shape

import numpy as np
from sklearn.datasets import load_digits
from scipy.spatial.distance import pdist
from sklearn.manifold.t_sne import _joint_probabilities
from scipy import linalg
from sklearn.metrics import pairwise_distances
from scipy.spatial.distance import squareform
from sklearn.manifold import TSNE
from matplotlib import pyplot as plt
import seaborn as sns

sns.set(rc={'figure.figsize':(18,12)})
# colors = ["#FF0B04", "#4374B3", "#388659", "#2bd9fe",
#           "#90aa86", "#824C71", "#1E3F20", "#94ECBE",
#           "#4C5760", "#A2708A", "#C1F7DC", "#824670",
#           "#FFDF64", "#877B66", "#D4E6B5", "#7C6C77",
#           "#D1D0A3", "#FFE787", "#1F2232", "#596475",
#           "#E88D67", "#7B8CDE", "#DCF763"]# Set your custom color palette
sns.set_palette(sns.color_palette(colors))
palette = sns.color_palette("bright", 23)

tsne = TSNE(perplexity=100)
X_embedded = tsne.fit_transform(X_train)
sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y_train, legend='full')

"""# 1. anova_chi_test_n_500"""

import numpy as np
import pandas as pd
from sklearn.feature_selection import SelectKBest, chi2 , f_classif,f_regression,mutual_info_classif,mutual_info_regression
from sklearn.svm import SVR

"""# Getting the genes from anova and chi2"""

#cancerXgene list


cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD","READ","SARC","STAD","THCA","THYM","UCEC"]
normal_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD","READ","SARC","STAD","THCA","THYM","UCEC"]

#reading data and doing work
for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_works/cancer/"+cancer_names[index]+".csv.gz", header=None, index_col=None)
  Normal = pd.read_csv("/content/drive/MyDrive/capstone_works/normal/"+normal_names[index]+".norm.csv.gz", header=None, index_col=None) 

  #droping sample names needed man whats your problem?
  Cancer = Cancer.drop(Cancer.index[0])
  Cancer = Cancer.drop(columns=[0])
  Normal = Normal.drop(Normal.index[0])
  Normal = Normal.drop(columns=[0])

  # Cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/cancer_wo_h/'+
  #               cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)
  # Normal.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/normal_wo_h/'+
  #               cancer_names[index]+'.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)

  #transpose
  Cancer_T = Cancer.T
  Normal_T = Normal.T

  #setting target
  Cancer_T["20501"] = 1.0
  Normal_T["20501"] = 0.0

  Cancer_T = Cancer_T.T
  Normal_T = Normal_T.T

  Cancer_T = Cancer_T.reset_index(drop=True)
  Normal_T = Normal_T.reset_index(drop=True)

  Cancer_T = Cancer_T.T
  Normal_T = Normal_T.T

  #print(Cancer_T)

  #dropping row
  Normal_T = Normal_T.drop(Normal_T.index[0])

  #concating
  X = pd.concat((Cancer_T,Normal_T),axis=0)
  # X = X.drop(columns = [0])
  # X = X.drop(X.index[0])
  x = X.iloc[:,:20501]
  y = X.iloc[:,20501]

  #print(x)
  #print(y)

  #selecting k value for anova
  k = 5

  #Anova test
  selector = SelectKBest(f_classif, k=k)
  selector.fit(x, y)
  cols_anova = selector.get_support(indices=True)
  np.save("/content/drive/MyDrive/capstone_work_part_2/std_npy/"+cancer_names[index],cols_anova)

"""# 2. Data Process

## Step 1
"""

import numpy as np
import pandas as pd
from sklearn.feature_selection import SelectKBest, chi2 , f_classif,f_regression,mutual_info_classif,mutual_info_regression
from sklearn.svm import SVR

"""# Frequency Check"""

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD","READ","SARC","STAD","THCA","THYM","UCEC"]

data = pd.read_csv("/content/drive/MyDrive/capstone_works/cancer/CHOL.csv.gz",header=None)
one_col = data.iloc[:,0:1]
one_col = one_col.drop(one_col.index[0])

gene_frequency = []
#reading data and doing work
for index in range(len(cancer_names)):
  DATA = np.load("/content/drive/MyDrive/capstone_work_part_2/std_npy/"+cancer_names[index]+".npy")
  # print(DATA)
  # print(DATA[0])
  #print(len(DATA))
  for i in range(len(DATA)):
    if (DATA[i] != 0):
      gene_frequency.append(one_col[0][DATA[i]])

np.save("/content/drive/MyDrive/capstone_work_part_2/std_npy/gene_frequency",gene_frequency)

"""## Step 2"""

import numpy as np
import json
import operator
import pandas as pd

gene_freq_count_list = np.load("/content/drive/MyDrive/capstone_work_part_2/std_npy/gene_frequency.npy")
unique_elements, counts_elements = np.unique(gene_freq_count_list, return_counts=True)
print("Unique genes:",len(unique_elements))

top_gene = {}

for i in range(len(unique_elements)):
	top_gene[unique_elements[i]] = counts_elements[i]
sorted_top_gene = dict(sorted(top_gene.items(), key=lambda item: item[1],reverse=True))
import csv
with open('/content/drive/MyDrive/capstone_work_part_2/std_npy/gene_frequency.csv', 'w') as f:
    for key in sorted_top_gene.keys():
        f.write("%s,%d\n"%(key,sorted_top_gene[key]))


np.save("/content/drive/MyDrive/capstone_work_part_2/data/genes_that_willbe_filtered",unique_elements)
data = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/std_npy/gene_frequency.csv",header=None)
counts = data.groupby(1).count()
counts.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/std_npy/gene_frequency_across_cancer.csv',header=None,index=None,index_label=None)

"""## Step 3

"""

## 1. select_gene_name_based_on_h1 ##

import numpy as np
import pandas as pd
import csv
import random

# importing the unique m genes name
unique_genes = np.load("/content/drive/MyDrive/capstone_work_part_2/data/genes_that_willbe_filtered.npy")

# reading and making a dictonary of counted numbers of genes based on their frequency
with open('/content/drive/MyDrive/capstone_work_part_2/std_npy/gene_frequency.csv', mode='r') as infile:
    reader = csv.reader(infile)
    gene_freq_dict = {rows[0]:rows[1] for rows in reader}

# print(type(unique_genes))
# print(unique_genes.shape)
# print(len(unique_genes))
# for gense in unique_genes:
# 	print(gense)

selected_genes = []
genes_with_freq_one = []
genes_with_freq_two = []
genes_with_freq_three = []
for gene in unique_genes:
  # if(gene_freq_dict[gene] == "1"):
  #   genes_with_freq_one.append(gene)
  # elif(gene_freq_dict[gene] == "2"):
  #   genes_with_freq_two.append(gene)
  # elif(gene_freq_dict[gene] == "3"):
  #   genes_with_freq_three.append(gene)
  # else:
  #   selected_genes.append(gene)
  selected_genes.append(gene)
  
#selected_genes = selected_genes[0:round(((len(selected_genes)/100) * 24.22))]
# selected_genes = selected_genes + genes_with_freq_three[0:round(((len(genes_with_freq_three)/100) * 25))] #55% taken
# selected_genes = selected_genes + genes_with_freq_two[0:round(((len(genes_with_freq_two)/100) * 15))] #45% taken
# selected_genes = selected_genes + genes_with_freq_one[0:round(((len(genes_with_freq_one)/100) * 5))] #55% taken

np.save("/content/drive/MyDrive/capstone_work_part_2/data/selected_genes_h2", selected_genes)

print(len(selected_genes))

gene_con = len(selected_genes)

"""## Step 4"""

## 2. select_gene_need_to_drop_h1 ##

import numpy as np
import pandas as pd
import csv
import random

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD","READ","SARC","STAD","THCA","THYM","UCEC"]

selected_genes = np.load("/content/drive/MyDrive/capstone_work_part_2/data/selected_genes_h2.npy")
print(len(selected_genes))
data = pd.read_csv("/content/drive/MyDrive/capstone_works/cancer/KICH.csv.gz",header=None)
header_gene_names =  data.iloc[:,0:1]
header_gene_names = header_gene_names.drop(header_gene_names.index[0])
header_gene_names.reset_index(drop=True, inplace=True)
# print(header_gene_names)
# print(header_gene_names.shape)

data_read = pd.read_csv(r"/content/drive/MyDrive/capstone_work_part_2/cancer_wo_h/KICH.txt.bz2",header=None, delimiter = '\t')
# print(data_read)
#print(header_gene_names.shape)
#print(data_read.shape)

# adding gene names in a std cancer data

frame0 = [data_read,header_gene_names]
data_cancer_early = pd.concat(frame0, axis = 1)
data_cancer_early = data_cancer_early.T
data_cancer_early.reset_index(drop=True, inplace=True)


cols_exist = []
cols_to_del = []

#print(data_cancer_early)

# selecting the genes that we need from "selected genes"
for i in range(20501):
	for j in range(len(selected_genes)):
		if(data_cancer_early[i][91] == selected_genes[j]):
			cols_exist.append(i)

# selecting the genes that we need to drop from "cols_to_exist"
for i in range(20501):
	if(i not in cols_exist):
		cols_to_del.append(i)

print(len(cols_to_del))
# saving the genes that we need to drop
np.save("/content/drive/MyDrive/capstone_work_part_2/data/genes_to_del_500k_h2",cols_to_del)

"""## Step 5"""

## 3. save_data_after_gene_del_h2 ##

import numpy as np
import pandas as pd
import csv
import random
from sklearn.preprocessing import StandardScaler

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD","READ","SARC","STAD","THCA","THYM","UCEC"]

# loading the genes that need to delete and saving the data again after removing the deleted genes
selected_genes = np.load("/content/drive/MyDrive/capstone_work_part_2/data/genes_to_del_500k_h2.npy")
print(len(selected_genes))

for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/cancer_wo_h/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = '\t')
  Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/normal_wo_h/"+
                       cancer_names[index]+".txt.bz2",header=None, delimiter = '\t')

  Cancer = Cancer.T
  Normal = Normal.T

  cancer = Cancer.drop(columns = selected_genes)
  normal = Normal.drop(columns = selected_genes)

  print(cancer.shape)
  print(normal.shape)

  cancer = cancer.T
  normal = normal.T

  std_scaler_can = StandardScaler()
  std_scaler_norm = StandardScaler()

  cancer = pd.DataFrame(std_scaler_can.fit_transform(cancer), columns=cancer.columns)
  normal = pd.DataFrame(std_scaler_norm.fit_transform(normal), columns=normal.columns)

  cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/mahin/data_k_50/cancer/'+
                cancer_names[index]+'unsmoothed.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)
  normal.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/mahin/data_k_50/normal/'+
                cancer_names[index]+'unsmoothed.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""## test train split for cancer (manually)"""

#for cancer

import numpy as np
import pandas as pd
import csv
import random
from sklearn.preprocessing import StandardScaler

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD","READ","SARC","STAD","THCA","THYM","UCEC"]
#len(cancer_names)
for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/mahin/data_k_50/cancer/"+
                       cancer_names[index]+"unsmoothed.txt.bz2",header=None, delimiter = '\t')
  print(cancer_names[index])
  print(len(Cancer.columns))
  val_train = round((len(Cancer.columns) * 75) / 100) 
  val_test = len(Cancer.columns) - val_train
  print(val_train)
  print(val_test)
  print()
  i = 0

  cols_for_test = []
  cols_for_train = []

  while i < val_test:
    x = random.randint(0,(len(Cancer.columns)-1))
    if x not in cols_for_test:
      cols_for_test.append(x)
      i += 1
  i = 0
  while i < val_train:
    x = random.randint(0,(len(Cancer.columns)-1))
    if x not in cols_for_test:
      if x not in cols_for_train:
        cols_for_train.append(x)
        i += 1

  test_cancer = Cancer.drop(columns = cols_for_train)
  train_cancer = Cancer.drop(columns = cols_for_test)

  test_cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/cancer/'+
                     cancer_names[index]+'unsmoothed.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)
  train_cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/pre_upsample_train_data/cancer/'+
                      cancer_names[index]+'unsmoothed.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""## test train split for normal (manually)"""

#for normal

import numpy as np
import pandas as pd
import csv
import random
from sklearn.preprocessing import StandardScaler

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH",
                "KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD",
                "READ","SARC","STAD","THCA","THYM","UCEC"]
#len(cancer_names)
for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/mahin/data_k_50/normal/"+
                       cancer_names[index]+"unsmoothed.txt.bz2",header=None, delimiter = '\t')
  print(cancer_names[index])
  print(len(Cancer.columns))
  if(len(Cancer.columns) != 2):
    val_train = round((len(Cancer.columns) * 75) / 100) 
    val_test = len(Cancer.columns) - val_train
    print(val_train)
    print(val_test)
    print()
    i = 0

    cols_for_test = []
    cols_for_train = []

    while i < val_test:
      x = random.randint(0,(len(Cancer.columns)-1))
      if x not in cols_for_test:
        cols_for_test.append(x)
        i += 1
    i = 0
    while i < val_train:
      x = random.randint(0,(len(Cancer.columns)-1))
      if x not in cols_for_test:
        if x not in cols_for_train:
          cols_for_train.append(x)
          i += 1

    test_cancer = Cancer.drop(columns = cols_for_train)
    train_cancer = Cancer.drop(columns = cols_for_test)

    test_cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/normal/'+
                      cancer_names[index]+'unsmoothed.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)
    train_cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/pre_upsample_train_data/normal/'+
                        cancer_names[index]+'unsmoothed.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)

  else:
    val_train = 2
    val_test = 1
    print(val_train)
    print(val_test)
    print()
    cols_for_train = [1]
    test_cancer = Cancer.drop(columns = cols_for_train)
    train_cancer = Cancer

    test_cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/normal/'+
                  cancer_names[index]+'unsmoothed.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)
    train_cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/pre_upsample_train_data/normal/'+
                        cancer_names[index]+'unsmoothed.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""## upsampling train data set in 3:1



"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from collections import Counter

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC","KICH",
                "KIRC","KIRP","LIHC","LUAD","LUSC","PAAD","PCPG","PRAD",
                "READ","SARC","STAD","THCA","THYM","UCEC"]

#len(cancer_names)

for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/pre_upsample_train_data/cancer/"+
                       cancer_names[index]+"unsmoothed.txt.bz2",header=None, delimiter = '\t')
  Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/pre_upsample_train_data/normal/"+
                       cancer_names[index]+"unsmoothed.txt.bz2",header=None, delimiter = '\t')

  # print(Cancer)
  # print(Normal)
  can_sample = len(Cancer.columns)
  norm_sample = len(Normal.columns)

  # print(can_sample)
  # print(norm_sample)
  
  Cancer = Cancer.T
  Normal = Normal.T

  if( norm_sample <= round(can_sample/3) ):
    ## adding target in the last col
    Cancer[str(gene_con)] = 1
    Normal[str(gene_con)] = 0
    
    #print(Cancer)

    frame = [Cancer,Normal]
    Data = pd.concat(frame,axis=0)

    #print(Data)

    x = Data.iloc[:,:gene_con]
    y = Data.iloc[:,gene_con]
    #print(x)
    #print(y)

    # summarize class distribution
    counter = Counter(y)
    print(counter)
    # transform the dataset
    oversample = SMOTE(k_neighbors=1, sampling_strategy=0.3333)
    X, y = oversample.fit_resample(x, y)
    # summarize the new class distribution
    counter = Counter(y)
    print(counter)
    #[1:,1:],index=data[1:,0],columns=data[0,1:]
    X = pd.DataFrame(data=X)
    y = pd.DataFrame(data=y)

    data = pd.concat([X,y], axis = 1)
    data = data.T
    data = data.reset_index(drop=True)
    #print(data)
    #print(len(data.columns))
    can = []
    norm = []
    for x in range(len(data.columns)):
      if(data[x][gene_con]==0):
        norm.append(x)
      elif(data[x][gene_con]==1):
        can.append(x)

    drops_for_can = []

    for x in range(len(data.columns)):
      if(x not in can):
        drops_for_can.append(x)
    Cancer = data.drop(columns=drops_for_can)

    drops_for_norm = []

    for x in range(len(data.columns)):
      if(x not in norm):
        drops_for_norm.append(x)
    Normal = data.drop(columns=drops_for_norm)

    Cancer = Cancer.drop(Cancer.index[gene_con])
    Normal = Normal.drop(Normal.index[gene_con])

    # Cancer = Cancer.T
    # Normal = Normal.T

    #print(Cancer)

    Cancer.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/train_data/cancer/'+
                  cancer_names[index]+'unsmoothed.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)
    Normal.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/train_data/normal/'+
                  cancer_names[index]+'unsmoothed.txt.bz2',compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""## merging bin train data"""

## 4. merging_data_h1 ##

import numpy as np
import pandas as pd

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC",
                "KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD",
                "PCPG","PRAD","READ","SARC","STAD","THCA","THYM",
                "UCEC"]

#reading data and doing work
cresult=pd.DataFrame()
nresult=pd.DataFrame()
for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/cancer/"+
                       cancer_names[index]+"unsmoothed.txt.bz2",header=None, delimiter = "\t")
  Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/normal/"+
                       cancer_names[index]+"unsmoothed.txt.bz2",header=None, delimiter = "\t")
  
  Cancer= Cancer.T
  Normal=Normal.T
  
  frames1 = [Cancer, cresult]
  cresult = pd.concat(frames1)
  
  frames2 = [Normal, nresult]
  nresult = pd.concat(frames2)
  
  print(cresult.shape)
  print(nresult.shape)
  
# merging all the cancer and normal data together and saving them  
cresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/train_data/bin_Cancer_'+str(k)+'unsmoothed.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

nresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/train_data/bin_Normal_'+str(k)+'unsmoothed.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""## merging bin test data"""

## 4. merging_data_h1 ##

import numpy as np
import pandas as pd

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC",
                "KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD",
                "PCPG","PRAD","READ","SARC","STAD","THCA","THYM",
                "UCEC"]

#reading data and doing work
cresult=pd.DataFrame()
nresult=pd.DataFrame()
for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/cancer/"+
                       cancer_names[index]+"unsmoothed.txt.bz2",header=None, delimiter = "\t")
  Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/normal/"+
                       cancer_names[index]+"unsmoothed.txt.bz2",header=None, delimiter = "\t")
  
  Cancer= Cancer.T
  Normal=Normal.T
  
  frames1 = [Cancer, cresult]
  cresult = pd.concat(frames1)
  
  frames2 = [Normal, nresult]
  nresult = pd.concat(frames2)
  
  print(cresult.shape)
  print(nresult.shape)
  
# merging all the cancer and normal data together and saving them  
cresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/bin_Cancer_'+str(k)+'unsmoothed.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

nresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/bin_Normal_'+str(k)+'unsmoothed.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""# tcga pan data merging

## train
"""

## HYPOTHESIS 1 ##

import numpy as np
import pandas as pd
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC",
                "KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD",
                "PCPG","PRAD","READ","SARC","STAD","THCA","THYM",
                "UCEC"]


#reading data and doing work
cresult=pd.DataFrame()
nresult=pd.DataFrame()
print(len(cancer_names))
for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/cancer/"+
                       cancer_names[index]+"unsmoothed.txt.bz2",header=None, delimiter = "\t")
  Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/train_data/normal/"+
                       cancer_names[index]+"unsmoothed.txt.bz2",header=None, delimiter = "\t")

  Cancer = Cancer.T
  Normal = Normal.T
  #print(Cancer)
  #print(Normal)

  Cancer['target'] = cancer_names[index]
  Normal['target'] = "normal"

  frames1 = [Cancer, cresult]
  cresult = pd.concat(frames1)
  
  frames2 = [Normal, nresult]
  nresult = pd.concat(frames2)
  
  print(cresult.shape)
  print(nresult.shape)
  

# merging all the cancer and normal data together separately and saving them  
cresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Cancer_'+str(k)+'unsmoothed.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

nresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Normal_'+str(k)+'unsmoothed.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""## test"""

## HYPOTHESIS 1 ##

import numpy as np
import pandas as pd
from collections import Counter
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import matthews_corrcoef
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE

cancer_names = ["BLCA","BRCA","CESC","CHOL","COAD","ESCA","HNSC",
                "KICH","KIRC","KIRP","LIHC","LUAD","LUSC","PAAD",
                "PCPG","PRAD","READ","SARC","STAD","THCA","THYM",
                "UCEC"]


#reading data and doing work
cresult=pd.DataFrame()
nresult=pd.DataFrame()
print(len(cancer_names))
for index in range(len(cancer_names)):
  Cancer = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/cancer/"+
                       cancer_names[index]+"unsmoothed.txt.bz2",header=None, delimiter = "\t")
  Normal = pd.read_csv("/content/drive/MyDrive/capstone_work_part_2/test_data/normal/"+
                       cancer_names[index]+"unsmoothed.txt.bz2",header=None, delimiter = "\t")

  Cancer = Cancer.T
  Normal = Normal.T
  #print(Cancer)
  #print(Normal)

  Cancer['target'] = cancer_names[index]
  Normal['target'] = "normal"

  frames1 = [Cancer, cresult]
  cresult = pd.concat(frames1)
  
  frames2 = [Normal, nresult]
  nresult = pd.concat(frames2)
  
  print(cresult.shape)
  print(nresult.shape)
  

# merging all the cancer and normal data together separately and saving them  
cresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Cancer_'+str(k)+'unsmoothed.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

nresult.to_csv(r'/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Normal_'+str(k)+'unsmoothed.txt.bz2',
               compression="bz2", sep='\t',header=None,index=None,index_label=None)

"""# TSNE

## Load Data test
"""

#train load
Cancer = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Cancer_"+str(k)+"unsmoothed.txt.bz2",
    header=None, delimiter = "\t")
Normal = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Normal_"+str(k)+"unsmoothed.txt.bz2",
    header=None, delimiter = "\t")
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
#print(Data)
X_train = Data.iloc[:,:gene_con]
y_train = Data.iloc[:,gene_con]

print(X_train.shape)
print(y_train.shape)

encoder = LabelEncoder()
encoder.fit(y_train)
encoded_Y = encoder.transform(y_train)
print(type(encoded_Y))

X_train['y'] = encoded_Y
np.random.seed(42)
rndperm = np.random.permutation(Data.shape[0])

pca = PCA(n_components=3)
pca_result = pca.fit_transform(X_train)
X_train['pca-one'] = pca_result[:,0]
X_train['pca-two'] = pca_result[:,1] 
X_train['pca-three'] = pca_result[:,2]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))

plt.figure(figsize=(16,10))
sns.scatterplot(
    x="pca-one", y="pca-two",
    hue="y",
    #palette=sns.color_palette('bright', X_train.y.unique().shape[0]),
    # palette = sns.color_palette('bright', 23),
    palette = sns.color_palette('husl', X_train.y.unique().shape[0]),
    data=X_train,
    legend="full",
    alpha=1
)

ax = plt.figure(figsize=(16,10)).gca(projection='3d')
ax.scatter(
    xs=X_train.iloc[rndperm,:]["pca-one"], 
    ys=X_train.iloc[rndperm,:]["pca-two"], 
    zs=X_train.iloc[rndperm,:]["pca-three"], 
    c=X_train.iloc[rndperm,:]["y"], 
    cmap='tab10'
)
ax.set_xlabel('pca-one')
ax.set_ylabel('pca-two')
ax.set_zlabel('pca-three')
plt.show()

import plotly.express as px
fig = px.scatter_3d(X_train, x='pca-one', y='pca-two', z='pca-three',color='y')
fig.show()

"""tsne

"""

Cancer = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Cancer_"+str(k)+"unsmoothed.txt.bz2",
    header=None, delimiter = "\t")
Normal = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/test_data/pan_Normal_"+str(k)+"unsmoothed.txt.bz2",
    header=None, delimiter = "\t")
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
#print(Data)
X_train = Data.iloc[:,:gene_con]
y_train = Data.iloc[:,gene_con]

print(X_train.shape)
print(y_train.shape)

import numpy as np
from sklearn.datasets import load_digits
from scipy.spatial.distance import pdist
from sklearn.manifold.t_sne import _joint_probabilities
from scipy import linalg
from sklearn.metrics import pairwise_distances
from scipy.spatial.distance import squareform
from sklearn.manifold import TSNE
from matplotlib import pyplot as plt
import seaborn as sns

sns.set(rc={'figure.figsize':(11.7,8.27)})
palette = sns.color_palette("bright", 23)

tsne = TSNE()
X_embedded = tsne.fit_transform(X_train)
sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y_train, legend='full', palette=palette)

"""## Load Data Train (Ei purata for unsmoothed)


"""

#train load
Cancer = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Cancer_"+str(k)+"unsmoothed.txt.bz2",
    header=None, delimiter = "\t")
Normal = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Normal_"+str(k)+"unsmoothed.txt.bz2",
    header=None, delimiter = "\t")
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
#print(Data)
X_train = Data.iloc[:,:gene_con]
y_train = Data.iloc[:,gene_con]

print(X_train.shape)
print(y_train.shape)

encoder = LabelEncoder()
encoder.fit(y_train)
encoded_Y = encoder.transform(y_train)
print(type(encoded_Y))

X_train['y'] = encoded_Y
np.random.seed(42)
rndperm = np.random.permutation(Data.shape[0])

pca = PCA(n_components=3)
pca_result = pca.fit_transform(X_train)
X_train['pca-one'] = pca_result[:,0]
X_train['pca-two'] = pca_result[:,1] 
X_train['pca-three'] = pca_result[:,2]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))

plt.figure(figsize=(16,10))
sns.scatterplot(
    x="pca-one", y="pca-two",
    hue="y",
    #palette=sns.color_palette('bright', X_train.y.unique().shape[0]),
    # palette = sns.color_palette('bright', 23),
    palette = sns.color_palette('husl', X_train.y.unique().shape[0]),
    data=X_train,
    legend="full",
    alpha=1
)

ax = plt.figure(figsize=(16,10)).gca(projection='3d')
ax.scatter(
    xs=X_train.iloc[rndperm,:]["pca-one"], 
    ys=X_train.iloc[rndperm,:]["pca-two"], 
    zs=X_train.iloc[rndperm,:]["pca-three"], 
    c=X_train.iloc[rndperm,:]["y"], 
    cmap='tab10'
)
ax.set_xlabel('pca-one')
ax.set_ylabel('pca-two')
ax.set_zlabel('pca-three')
plt.show()

import plotly.express as px
fig = px.scatter_3d(X_train, x='pca-one', y='pca-two', z='pca-three',color='y')
fig.show()

"""tsne

"""

Cancer = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Cancer_"+str(k)+"unsmoothed.txt.bz2",
    header=None, delimiter = "\t")
Normal = pd.read_csv(
    "/content/drive/MyDrive/capstone_work_part_2/train_data/pan_Normal_"+str(k)+"unsmoothed.txt.bz2",
    header=None, delimiter = "\t")
Normal = Normal.drop(Normal.index[0])
frame = [Cancer,Normal]
Data = pd.concat(frame,axis=0)
Data = Data.drop(Data.index[0])
#print(Data)
X_train = Data.iloc[:,:gene_con]
y_train = Data.iloc[:,gene_con]

print(X_train.shape)
print(y_train.shape)

import numpy as np
from sklearn.datasets import load_digits
from scipy.spatial.distance import pdist
from sklearn.manifold.t_sne import _joint_probabilities
from scipy import linalg
from sklearn.metrics import pairwise_distances
from scipy.spatial.distance import squareform
from sklearn.manifold import TSNE
from matplotlib import pyplot as plt
import seaborn as sns

sns.set(rc={'figure.figsize':(11.7,8.27)})
# colors = ["#FF0B04", "#4374B3", "#388659", "#2bd9fe",
#           "#90aa86", "#824C71", "#1E3F20", "#94ECBE",
#           "#4C5760", "#A2708A", "#C1F7DC", "#824670",
#           "#FFDF64", "#877B66", "#D4E6B5", "#7C6C77",
#           "#D1D0A3", "#FFE787", "#1F2232", "#596475",
#           "#E88D67", "#7B8CDE", "#DCF763"]# Set your custom color palette
sns.set_palette(sns.color_palette(colors))
#palette = sns.color_palette("bright", 23)

tsne = TSNE(perplexity=100)
#X_embedded = tsne.fit_transform(X_train)
sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y_train, legend='full')